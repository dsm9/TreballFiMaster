{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Tipus incidència 'No ha impartit classe a aquest grup'\n",
    "\n",
    "This notebook creates a evaluates a model to detect the issue 'No ha impartit classe a aquest grup'.\n",
    "\n",
    "It will be created a model to each language: catalan, spanish and english.\n",
    "\n",
    "Only are treated comments of type 'P : Professor'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load(\"ca_fasttext_wiki\")\n",
    "#nlp = spacy.load(\"es_core_news_sm\")\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads information from preprocessed file to create de train and test data\n",
    "\n",
    "def load_data(limit = 0, split = 0.8, language = \"ca\"):\n",
    "\n",
    "    if (debug >= 1):\n",
    "        print (\"LOAD_DATA\")\n",
    "        \n",
    "    # Load data from file\n",
    "    file = \"comentaris_\" + language + \".csv\"\n",
    "    data = pd.read_csv(pathdest + file)\n",
    "    if (debug >= 2):\n",
    "        print (\"Original data:\")\n",
    "        display (data.sample(5))\n",
    "\n",
    "    # Calculates label and filter rows to be used    \n",
    "    data_prof = data[data.TipusPregunta == \"P\"][[\"Comentari\",\"TipusIncidencia\"]]\n",
    "    if (debug >= 1):\n",
    "        print(\"Original data: \", data_prof.shape[0])\n",
    "        \n",
    "    if (debug >= 2):\n",
    "        print (\"Filtered data:\")\n",
    "        display (data_prof.sample(5))    \n",
    "\n",
    "    # Calculates tuples row\n",
    "    # Converts: label=True -> {\"POSITIVE\": True, \"NEGATIVE\": False}\n",
    "    # label=False -> {\"POSITIVE\": False, \"NEGATIVE\": True}\n",
    "\n",
    "    data_prof[\"label\"] = data_prof[\"TipusIncidencia\"] == \"No ha impartit classe a aquest grup\"\n",
    "    data_prof[\"tuples\"] = data_prof.apply(lambda row: (row[\"Comentari\"], {\"POSITIVE\": bool(row[\"label\"]), \"NEGATIVE\": not bool(row[\"label\"])}), axis=1)    \n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples dataframe:\")\n",
    "        display (data_prof.sample(5))\n",
    "\n",
    "    # Select positive cases\n",
    "    data_true = data_prof[data_prof[\"label\"]==True]\n",
    "    if (debug >= 2):\n",
    "        print (\"Data True cases:\", data_true.shape[0])\n",
    "        \n",
    "    train_data_true = data_true[\"tuples\"].tolist()\n",
    "    random.shuffle(train_data_true)\n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples list true:\")\n",
    "        print (train_data_true[:5])  \n",
    "        \n",
    "    # Split text and label of true cases into two lists\n",
    "    texts_true, cats_true = zip(*train_data_true)\n",
    "    if (debug >= 2):\n",
    "        print (\"Texts True cases:\")\n",
    "        print (texts_true[0:5])\n",
    "        print (\"Cats False cases:\")\n",
    "        print (cats_true[0:5])\n",
    "    \n",
    "    # Size of train_data_true and test_data_true\n",
    "    split_true = int(len(train_data_true) * split)\n",
    "    if (debug >= 1):\n",
    "        print (\"Train data True:\", split_true, \", Test data True: \", len(train_data_true)-split_true)   \n",
    "        \n",
    "    # Select negative cases\n",
    "    data_false = data_prof[data_prof[\"label\"]==False]\n",
    "    if (debug >= 2):\n",
    "        print (\"Data False cases:\", data_false.shape[0])\n",
    "        \n",
    "    train_data_false = data_false[\"tuples\"].tolist()\n",
    "    random.shuffle(train_data_false)\n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples list false:\")\n",
    "        print (train_data_false[:5])  \n",
    "        \n",
    "    # Split text and label of false cases into two lists\n",
    "    texts_false, cats_false = zip(*train_data_false)\n",
    "    if (debug >= 2):\n",
    "        print (\"Texts True cases:\")\n",
    "        print (texts_true[0:5])\n",
    "        print (\"Cats False cases:\")\n",
    "        print (cats_true[0:5])\n",
    "    \n",
    "    # Size of train_data_false and test_data_false\n",
    "    if (limit > 0) & ((len(train_data_false) + len(train_data_true)) * split > limit):\n",
    "        train_split_false = int(limit - len(train_data_true) * split) \n",
    "        test_split_false = int(len(train_data_false) * (1 - split))\n",
    "    else:\n",
    "        train_split_false = int(len(train_data_false) * split)\n",
    "        test_split_false = int(len(train_data_false) * (1 - split))\n",
    "        \n",
    "    if (debug >= 1):\n",
    "        print (\"Train data False:\", train_split_false, \", Test data False: \", test_split_false)   \n",
    "    \n",
    "    \n",
    "    # Mix true and false cases and split in train and devel\n",
    "    # All the true cases are included\n",
    "    train_texts = texts_true[:split_true] + texts_false[:train_split_false]\n",
    "    train_cats = cats_true[:split_true] + cats_false[:train_split_false]\n",
    "    test_texts = texts_true[split_true:] + texts_false[-test_split_false:]\n",
    "    test_cats = cats_true[split_true:] + cats_false[-test_split_false:]\n",
    "    if (debug >= 1):\n",
    "        print (\"Train texts: \", len(train_texts), \", Test texts: \", len(test_texts))\n",
    "        \n",
    "    # Return train data and test data\n",
    "    return (train_texts, train_cats), (test_texts, test_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the level of accuracy using the test set to compare the prediction with the label defined by the user \n",
    "# Obtains the indicators: Precission (p), Recall (r) and F-score (f)\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    fp_list = list()\n",
    "    fn_list = list()\n",
    "    \n",
    "    if (debug == 1):\n",
    "        print (\"EVALUATE\")\n",
    "        \n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "                fp_list.append(doc)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fp: \", doc)\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "                fn_list.append(doc)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fn: \", doc)                \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score, \n",
    "            \"false_positive\": fp_list, \"false_negative\": fn_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the training information, transforms it, trains the model with this set of data, evaluate the result \n",
    "# and saves the resulting model\n",
    "\n",
    "def train_model(model=None, language=\"ca\", target_loss=0.001, n_texts=2000):\n",
    "    \n",
    "    if (debug == 1):\n",
    "        print (\"TRAIN MODEL\")\n",
    "        \n",
    "    # Load the model form spacy\n",
    "    nlp = spacy.load(model)\n",
    "\n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    # add label to text classifier\n",
    "    textcat.add_label(\"POSITIVE\")\n",
    "    textcat.add_label(\"NEGATIVE\")\n",
    "        \n",
    "    # load training and test data\n",
    "    (train_texts, train_cats), (dev_texts, dev_cats) = load_data(n_texts, 0.8, language)\n",
    "\n",
    "    if debug:\n",
    "        print(\n",
    "            \"Using {} examples ({} training, {} evaluation)\".format(\n",
    "                n_texts, len(train_texts), len(dev_texts)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # converts the data to the format:\n",
    "    # (text, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}))\n",
    "    train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "    if debug:\n",
    "        print (\"Train_data: \")\n",
    "        print (train_data[:5])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "#        if init_tok2vec is not None:\n",
    "#            with init_tok2vec.open(\"rb\") as file_:\n",
    "#                textcat.model.tok2vec.from_bytes(file_.read())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Training the model...\")\n",
    "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "        loss = 100\n",
    "        prev_loss = 1000\n",
    "        while (loss > target_loss) | (prev_loss - loss > target_loss):\n",
    "            prev_loss = loss\n",
    "#        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=batch_sizes)\n",
    "            count = 0\n",
    "            for batch in batches:\n",
    "                if (debug >= 2):\n",
    "                    print (\"Batch: \")\n",
    "                    print (batch)\n",
    "                texts, annotations = zip(*batch)\n",
    "                if (count == 0):\n",
    "                    count = 1\n",
    "                    print (texts)\n",
    "\n",
    "                # Eliminación del 20% de los casos para evitar generalizaciones\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print(\n",
    "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(  # print a simple table\n",
    "                    losses[\"textcat\"],\n",
    "                    scores[\"textcat_p\"],\n",
    "                    scores[\"textcat_r\"],\n",
    "                    scores[\"textcat_f\"],\n",
    "                )\n",
    "            )  \n",
    "            loss = losses[\"textcat\"]\n",
    "            \n",
    "        print ()\n",
    "        print (\"False positives:\")\n",
    "        print (scores[\"false_positive\"])\n",
    "        print ()\n",
    "        print (\"False negatives\")\n",
    "        print (scores[\"false_negative\"])\n",
    "            \n",
    "    # test the trained model\n",
    "    print (\"\")\n",
    "    print (\"Some examples: \")\n",
    "    test_texts ={\"ca\": [\"Costa que pengi els materials acordats al campus\",\n",
    "                    \"No he tingut aquesta professora\",\n",
    "                    \"No ha impartit classe a aquest grup\",\n",
    "                    \"No ha corregit examens fets a octubre, i estem al mes de gener.\"],\n",
    "            \"es\": [\"No he tenido contacto\", \n",
    "                   \"Muy  buenas clases\",\n",
    "                   \"No nos dio clases\",\n",
    "                   \"No vimos a en clase a este docente\"\n",
    "                   \"No se ha adaptado a la actual situación\"\n",
    "                  ],\n",
    "            \"en\": [\"I haven't had this professor\",\n",
    "                   \"We don't know this person\",\n",
    "                   \"He isn't a good professor\",\n",
    "                   \"We had only a few lessons\"\n",
    "                  ]\n",
    "        }     \n",
    "    for test_text in test_texts[language]:\n",
    "        doc = nlp(test_text)\n",
    "        print(test_text, doc.cats)\n",
    "    print (\"\")\n",
    "    \n",
    "    # Save de model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(pathmodel + language)\n",
    "    print(\"Saved model to\", pathmodel + language)\n",
    "        \n",
    "    # test the saved model\n",
    "    print(\"Loading from\", pathmodel+ language)\n",
    "    nlp2 = spacy.load(pathmodel +  language)\n",
    "    for test_text in test_texts[language]:\n",
    "        doc2 = nlp2(test_text)\n",
    "        print(test_text, doc2.cats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathori = \"../data/original\"\n",
    "pathdest = \"../data/preprocessed/\"\n",
    "pathmodel = \"../data/models/model1/\"\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING LANGUAGE: ca\n",
      "Model: ca_fasttext_wiki\n",
      "TRAIN MODEL\n",
      "LOAD_DATA\n",
      "Original data:  3985\n",
      "Train data True: 59 , Test data True:  15\n",
      "Train data False: 1940 , Test data False:  782\n",
      "Train texts:  1999 , Test texts:  797\n",
      "Using 2000 examples (1999 training, 797 evaluation)\n",
      "Train_data: \n",
      "[('No he tingut a aquest professor', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('No l’he tingut', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('no L´he tingut', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('Només va venir un dia a la sortida de camp. ', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), (\"No l'hem tingut\", {'cats': {'POSITIVE': True, 'NEGATIVE': False}})]\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "(\"Malauradament un cop iniciat el confinament, tot ha estat fum. Ha desaparegut la seva persona. Algun correu ha fet respecte el treball a entregar però poca cosa. L'examen es basa en lectures eternes que els alumnes hem de preparar de manera autonoma. \", \"Un nivell d'exigencia massa elevat. \", \"Durant les classes online, ha confiat massa en ensenyar-nos el temari mitjançant videos. S'agrairia que es tinguessin com a eina apart per ajudar l'alumne a la hora d'estudiar, i que en el moment de fer classe ens ho expliqués ella mateixa.\", 'Amb la situació del Covid-19, la seva adaptació cap a nosaltres ha estat excel-lent. ')\n",
      "EVALUATE\n",
      "0.931\t0.800\t0.533\t0.640\n",
      "(' El que no pot ser és que faci una avaluació amb un temps tan limitat. Per molt que tinguis coneixements, no tens opció a mostrar-los. Simplement cal observar les notes de la prova. En les quals sol aproven 4 persones i la que te millor nota és un 6. És VERGONYÓS!\\r', \"Continguts necessaris i interessants però classes una mica massa magistrals per estar dins un màster d'innovació.\", \"Ha hagut un excés d'exigència en quant a les tasques demanades setmanalment i la llargada d'aquestes. Moltes semblaven més aviat un treball de l'assignatura que no una pràctica per desenvolupar un tema concret. Fins gairebé el final del semestre no es va modificar la quantitat desmesurada de treball fet que ens ha portat a dedicar menys hores a altres tasques que tenim pendents com el Treball de final de grau. Entenc que no ha estat una situació fàcil de gestionar, però m'agradaria que els alumnes fossim més escoltats. \", \"No tinc res a dir, a complert amb el que he respost. L'únic que poder miraria de que tingués les notes de pràctiques amb temps ja que així ens podem guiar si la resta de les que fem anem per bon camí o no. Però per la resta tot bé. \", \"Eloi Garí és un excel·lent professor. Intenta que els alumnes treguin el màxim de la seva assignatura i ho aconsegueix, a més de fer-la interessant. S'ha adaptat molt bé a la situació actual i ens facilita l'estudi i l'aprenentatge.\", \"M'ha agradat molt com explica la assignatura\")\n",
      "EVALUATE\n",
      "0.153\t0.750\t0.600\t0.667\n",
      "(\"El tracte amb l'alumnat és de superioritat i no permet comentar certs dubtes, quan els planteges en ocasions et fa comentaris innecessaris i fora de lloc.\", \"Durant aquest període de confinament, hem tingut considerables problemes amb aquest professor a causa de no arribar a acords en els quals ambdues parts estiguéssim satisfetes. Ha ignorat totalment les nostres propostes i opinions i ha decidit dur a terme les accions que ha considerat oportunes, sense ni tan sols valorar si aquestes ens perjudicaven més o no en aquesta situació extraordinària. Entre elles es podria incloure el mètode avaluatiu d'examen tipus test via online de 40 preguntes en 15 minuts.\", 'Una dels aspectes a millorar és la manera com puntua la Laura, ja que és molt exigent i si et deixes una PARAULA ja descompte punts. \\r\\nPer lo altre, trobo que és una bona professora i molt atenta dels seus alumnes!!!!!!!!!\\r\\n', \"Hauria d'explicar el temari més enllà del que està escrit en la presentació de classe. A més, hauria de portar un ritme més calmat durant les explicacions. \", 'Ha estat un professor present des del minut 0 de l’assignatura i ens ha deixat clar tot el que fariem des d’aquell moment, és una qualitat que valorem molt. ', \"Dir que tot i la situació actual de COVID-19, com a responsable de l'assignatura ha sigut l'únic professor que ha buscat alternatives per a poder dur un ritme de classe més formal i correcte (classes virtuals). Com a aspecte a millorar, el fet de no donar-nos suficients pautes abans de l'examen i que apenes sapiguem el que entra i hem d'estudiar previ a aquest.\", \"Inseguretat a l'hora d'aclarir conceptes, explica conceptes de forma diferent a la resta del professors de l'assignatura, és necessari més ordre a l'hora d'explicar les diapositives.\", \"Igual que amb el Dr. Yuguero, és difícil tenir una opinió sobre si el Dr. Pifarré compleix amb els horaris o si utilitza mètodes adequats. De totes maneres, les activitats pertinents a la seva part de l'assignatura personalment em semblen una bona estratègia per a preparar als alumnes per a tenir pensament crític i formar-se a l'hora de fer exposicions en anglès.\")\n",
      "EVALUATE\n",
      "0.229\t0.706\t0.800\t0.750\n",
      "('Té tendència a la discriminació a certs alumnes de classe, fins i tot aquestes maneres de fer estan relacionades amb un caràcter xenòfob.\\r\\n\\r', \"A més puntua d'una forma extranya, ja que no especifica el que vol a l'activitat i després les noes són baixes.\\r\\nPel que fa a les classes presencials, trobo que és molt bona professora, ja que busca alternatives i fa les classes molt dinàmiques, però amb la situació del COVID-19, les activitats estaven bé, però la forma d'avaluar massa baixa.\", 'Molt ordenada i responsable. És una tranquilitat fer classes amb ella perquè saps que tot ho entendràs bé.', \"A vegades mostra una actitud prepotent e incomoda a l'hora de participar en les classes.\", \"Organització a l'hora de treballar i dinamitzar activitats\\r\\n\", \"Ha tingut una actitud molt bona per l'assignatura, tot i que el temari que es dona, la veritat és que és molt,molt teòric i difícil de interioritzar\", 'Crec que deuria especificar més amb el temari i fer una relació més directa entre alumne-professor, ja que crec que és molt distant.', 'La Maite ha estat una professora molt entregada i se li nota que gaudeix del que ensenya. Sempre ha tingut en compte les nostres peticions, sobretot durant el temps de confinament. ', \"Expluca molt bé, i es un bon professor, pero la dificultat de les proves d'avaluació es massa alta, inclús dins del grau d'enginyeria. \", \"És l'únic professor que hem tingut que des de el primer moment que va començar la situació del COVID-19 s'ha adaptat a la situació i ens ha fet classe, ha creat sales individuals per cada grup de treball per poder treballar les activitats i ell estar a la sala comuna per si teniem dubtes. Ens ha plantejat un examen adaptat a la situació... Ens hem sentit recolçats per ell i ho valorem molt, sobretot en aquesta situació de incerteça.\")\n",
      "EVALUATE\n",
      "0.014\t0.706\t0.800\t0.750\n",
      "(\"Donar un resultat en els exercicis serviria per anar treballant millor i no quedarse tan encallat en mig d'un problema per veure si et dona semblant, però no t'ho dona. \\r\\nEtc, etc.\", 'Juanfran és un bon profe i si et pot ajudar ho farà. Sempre està obert a noves propostes i això fa que potser volguem aprendre més.', \"Vaig demanar una revisió d'examen i no me la va concedir. \", \"El fet de tindre un examen i fer a soles una classe el dia d'abans i de forma molt ràpida crec que no m'ha ajudat a aprendre sobre l'examen, sobre el temari d'aquesta evaluació. Hauria de fer més classes virtuals per al pròxim examen i baixar el % en el primer examen ja que vam tindre que estudiar eixe examen sense la seua ajuda. \", \"Molt mala organització i falta d'explicació. Les classes no s'encaren bé i fan que la gent desconecti i no entengui res. \", 'Explica molt bé i ens ha estrucuturat l’assignatura de la millor forma possible. L’ha encarat al nostre àmbit i posa exemples d’això. ', \"La metodologia de les seves classes és una mica tradicional, però s'ha adaptat molt bé a les circumstàncies i ens ha facilitat en tot moment la feina alhora que sempre està disposat a resoldre dubtes, tant per correu de forma ràpida i clara com a les videoconferències. Compleix sempre amb els horaris establerts i transmet la seva passió als alumnes, fet que afavoreix la motivació dels alumnes. \", 'En referencia a la professora, és molt bona comunicadora i pels alumnes que dret no és el nostre punt fort, les seves explicacions ens han facilitat molt el seguiment de l’assignatura. També és valora el trivial, els tutorials...', \"Remarca molt bé els conceptes per tal de fer-los entendre. Això ajuda molt a l'estudiant.\", \"Es dels profes que millor ha adaptat l'assignatura al curs tenint en compte els efectes de la pandemia\", \"Degut a les circumstàncies de la Covid-19 pràcticament no l'hem conegut, ens ha enviat algun vídeo explicatiu però poc més. S'hauria agraït alguna tutoria per videoconferència pel que fa al desenvolupament del treball en grup.\", \"Penso que vam trigar molt a fer les videoconferències virtuals per tal d'explicar el temari de l'examen. \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATE\n",
      "0.002\t0.667\t0.800\t0.727\n",
      "(\"A l'hora d'explicar putser dona per suposat informació que en teoria no sabem del tot, i moltes de les seves classes va massa ràpid i no dona temps a adquirir les idees sobre el que està explicant.\", 'Un bon professor. ', 'No ha estat el meu tutor, no puc avaluar-lo.', \"Estic molt contenta amb ambdues professores. han sigut molt empàtiques en aquesta situació tant difícil, i ens han facilitat un munt les eines per a poder continuar amb l'assignatura\", 'Molt correcte', \"Ha tingut una actitud molt bona per l'assignatura, tot i que el temari que es dona, la veritat és que és molt,molt teòric i difícil de interioritzar\", \"En les classes ja és un professor que no explica bé i que ens deixa molta llibertat als alumnes, que això últim en certa manera ja està bé. El problema més gran ha estat durant el confinament: ens ha deixat bastant de banda, se'ns ha dit que és per la quantitat de feina que tenia, sobretot amb altres assignatures. Segur que es veritat. Potser no se'n haurien de donar tantes.\", 'Al principi estava molt tensa amb nosaltres, però ens vam anar coneixent i finalment va ser molt molt comprensiva amb nosaltres. \\r\\nNo tinc res dolent a dir sobre ella, al contrari. ', 'No ha fet cap classe online. ', 'La Judit és una professora excelent! És atenta, amable, respectuosa i molt propera. Hauriem de poder tindre més professores com ella', ' Estic molt disgustat amb aquesta asignatura i sobretot amb la professora. Les seves classes no les entén ni ella, no segueix cap contingut i fa fer activitats sense sentit. ', 'ell amb tot el morro va dir: \"la resta de grups que heu entes?', 'Bona docència presencial. ', 'Es una bona professora, explica molt bé els continguts, clarament i amb imatges gràfiques. Gràcies a ella aprenem en la part de dietoterapia.')\n",
      "EVALUATE\n",
      "0.001\t0.667\t0.800\t0.727\n",
      "('El molt bona professora i la Luisa també. Molt properes. Es nota que en saben molt i que els hi agrad ensenyar.', \"No tinc cap queixa al respecte, però hauria d'innovar els seus recursos i viure una mica més de prop la docència. Sap molt però no sap transmetre els coneixements, i tampoc té gaire ganes de fer-ho. A més, tampoc és gaire flexible a l'hora de millorar la situació dels alumnes. Porta fent els mateixos exàmens 40 anys.\", \"El Roger ens ha enviat el text del temario que hauria explicat a classe, a més d'algún vídeo explicatiu i els powers. També ha contestant ràpidament quan li hem preguntar alguna cosa i ha accedit a moure la data de l'examen final per tal d'ajudar-nos, ja que la situación en la que ens trobem no és gens fácil.\", \"Dir que tot i la situació actual de COVID-19, com a responsable de l'assignatura ha sigut l'únic professor que ha buscat alternatives per a poder dur un ritme de classe més formal i correcte (classes virtuals). Com a aspecte a millorar, el fet de no donar-nos suficients pautes abans de l'examen i que apenes sapiguem el que entra i hem d'estudiar previ a aquest.\", 'El sistema de sessions grabades i consultes durant la setmana, és un molt bon sistema per seguir les classes durant el confinament.', 'Només llegeix els apunts que tenim, la qual cosa, anar a classe o no és el mateix', 'Actitud pessima. Llegeix i rellegeix el pwp. No sento que aprengui res. Lectures innecessàries. ', \"Considero que ha estat un bon professor ja que s'ha adaptat en tot moment a les situacions que ens hem trobat, ens ha donat molts recursos  per a treballar l'assginatura i l'aprenentatge ha estat tant pràctic com teòric (considero que és un aspecte fonamental).  Crec que la seva actuació ha estat excel·lent.  \", \"Personalment trobo que el mètode d'ensenyament i avaluació de la part impartida pel professor Colinas no resulta efectiu. Penso que, malgrat l'esforç que fa el professor per adaptar el mètode d'ensenyament a l'actualitat, no s'aconsegueix transmetre els coneixements, i l'aprenentatge per part de l'alumnat és molt poc. A més, el mètode d'avaluació dóna peu a la confrontació entre alumnes degut a la competitivitat que suposa, i la forma amb què es corregeixen les activitats sovint és molt arbitrària i poc fonamentada. \\r\\nL'actitud cap a l'alumne hauria de ser més respectuosa.\\r\\nCrec que el professor Carlos Colinas és una persona més que capacitada per realitzar una gran tasca docent i crec que es pot aprendre molt d'ell, però sens dubte, aquest no és el mètode idoni per fer-ho i convé un canvi urgent en la metodologia d'aquesta part de l'assignatura.\", 'Degut al COVID-19, no hem pogut trobar-nos ni realitzar classes', \"Molt coherent. M'ha agradat molt com a professor, n'he après molt.\\r\\n\", \" buscar una notícia de premsa sobre algun patògen. Aquí la majoria tenim un 0 per motius com que hem copiat, cosa que no entenem de qui devem haver copiat...o perquè resulta que no és un patògen, cosa d'esperar ja que encara no ens ha explicat absolutament res de patògens i no sabem diferenciar-los ni res. O per altres motius absurds. Directament un 0 rodó.\\r\\n\", \"Degut a l'estat d'emergència sanitària, no hem pogut assisstir a les seves classes, però ens ha donat el material necessari per assolir els continguts de manera telemàtica. Tanmateix, personalment m'hagués agradat que es poguessin continuar fent les classes online mitjançant la videotrucada. \", \"Vaig demanar una revisió d'examen i no me la va concedir. \", \"El professor que és més proper als alumnes i que s'interessa més per els problemes que pots tenir. Et tracta com un més i no amb la superioritat de ser professor i saberho tot. Sense cap mena de dubte el millor professor de tota l'assignatura. Més professors com ell siusplau\", \"La Clara és una crack! M'ha agradat molt la manera en que ens ha presentat la història i els recursos que ens ha facilitat per treballar-la amb els nens i nenes. Té molts coneixments i transmetre'ls!\")\n",
      "EVALUATE\n",
      "0.000\t0.750\t0.800\t0.774\n",
      "\n",
      "False positives:\n",
      "[No l’hem tingut, No l'hem tingut a aquesta persona (Karen), hem tingut al Marc a història, Només vam tenir-la un dia, No compleix les seves funcions com a coordinadora de Màster.]\n",
      "\n",
      "False negatives\n",
      "[No la tinc, No en tinc ni la més remota idea de qui és vostè, però se li ha de reconèixer que ara per ara és el que més sentit comú ha mostrat al no manar-nos seminaris absurds ni fer-nos perdre el temps amb informació obvia en power points. Moltes gràcies., Degut a la situació d'emergencia no he tingut el plaer de gaudier de les clases de la profesora, així que no puc fer una valoració amb criteri ]\n",
      "\n",
      "Some examples: \n",
      "Costa que pengi els materials acordats al campus {'POSITIVE': 4.34029152529547e-06, 'NEGATIVE': 0.9999957084655762}\n",
      "No he tingut aquesta professora {'POSITIVE': 0.9999886751174927, 'NEGATIVE': 1.1268468369962648e-05}\n",
      "No ha impartit classe a aquest grup {'POSITIVE': 0.9948862195014954, 'NEGATIVE': 0.005113802384585142}\n",
      "No ha corregit examens fets a octubre, i estem al mes de gener. {'POSITIVE': 1.626603989279829e-05, 'NEGATIVE': 0.9999837875366211}\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/model1/ca'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-70948a4cff9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAINING LANGUAGE: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Model: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-05e7ff12144d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, language, target_loss, n_texts)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Save de model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mto_disk\u001b[0;34m(self, path, exclude, disable)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mto_disk\u001b[0;34m(path, writers, exclude)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwriters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/model1/ca'"
     ]
    }
   ],
   "source": [
    "n_iter = 5\n",
    "target_loss = 0.001\n",
    "n_texts = 2000\n",
    "languages = {\"ca\":\"ca_fasttext_wiki\", \"es\":\"es_core_news_sm\", \"en\":\"en_core_web_sm\" }\n",
    "#languages = {\"ca\":\"ca_fasttext_wiki\"}\n",
    "\n",
    "for language in languages:\n",
    "    model = languages[language]\n",
    "    \n",
    "    print()\n",
    "    print (\"TRAINING LANGUAGE: \" + language)    \n",
    "    print (\"Model: \" + model)\n",
    "    train_model (model, language, target_loss, n_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
