{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Tipus incidÃ¨ncia 'No ha impartit classe a aquest grup'\n",
    "\n",
    "This notebook creates a evaluates a model to detect the issue 'No ha impartit classe a aquest grup'.\n",
    "\n",
    "It will be created a model to each language: catalan, spanish and english.\n",
    "\n",
    "Only are treated comments of type 'P : Professor'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load(\"ca_fasttext_wiki\")\n",
    "#nlp = spacy.load(\"es_core_news_sm\")\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads information from preprocessed file to create de train and test data\n",
    "\n",
    "def load_data(limit = 0, split = 0.8, language = \"ca\"):\n",
    "\n",
    "    if (debug >= 1):\n",
    "        print (\"LOAD_DATA\")\n",
    "        \n",
    "    # Load data from file\n",
    "    file = \"comentaris_\" + language + \".csv\"\n",
    "    data = pd.read_csv(pathdest + file)\n",
    "    if (debug >= 2):\n",
    "        print (\"Original data:\")\n",
    "        display (data.sample(5))\n",
    "\n",
    "    # Calculates label and filter rows to be used    \n",
    "    data_prof = data[data.TipusPregunta == \"P\"][[\"Comentari\",\"TipusIncidencia\"]]\n",
    "    if (debug >= 1):\n",
    "        print(\"Original data: \", data_prof.shape[0])\n",
    "        \n",
    "    if (debug >= 2):\n",
    "        print (\"Filtered data:\")\n",
    "        display (data_prof.sample(5))    \n",
    "\n",
    "    # Calculates tuples row\n",
    "    # Converts: label=True -> {\"POSITIVE\": True, \"NEGATIVE\": False}\n",
    "    # label=False -> {\"POSITIVE\": False, \"NEGATIVE\": True}\n",
    "\n",
    "    data_prof[\"label\"] = data_prof[\"TipusIncidencia\"] == \"No ha impartit classe a aquest grup\"\n",
    "    data_prof[\"tuples\"] = data_prof.apply(lambda row: (row[\"Comentari\"], {\"POSITIVE\": bool(row[\"label\"]), \"NEGATIVE\": not bool(row[\"label\"])}), axis=1)    \n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples dataframe:\")\n",
    "        display (data_prof.sample(5))\n",
    "\n",
    "    # Select positive cases\n",
    "    data_true = data_prof[data_prof[\"label\"]==True]\n",
    "    if (debug >= 2):\n",
    "        print (\"Data True cases:\", data_true.shape[0])\n",
    "        \n",
    "    train_data_true = data_true[\"tuples\"].tolist()\n",
    "    random.shuffle(train_data_true)\n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples list true:\")\n",
    "        print (train_data_true[:5])  \n",
    "        \n",
    "    # Split text and label of true cases into two lists\n",
    "    texts_true, cats_true = zip(*train_data_true)\n",
    "    if (debug >= 2):\n",
    "        print (\"Texts True cases:\")\n",
    "        print (texts_true[0:5])\n",
    "        print (\"Cats False cases:\")\n",
    "        print (cats_true[0:5])\n",
    "    \n",
    "    # Size of train_data_true and test_data_true\n",
    "    split_true = int(len(train_data_true) * split)\n",
    "    if (debug >= 1):\n",
    "        print (\"Train data True:\", split_true, \", Test data True: \", len(train_data_true)-split_true)   \n",
    "        \n",
    "    # Select negative cases\n",
    "    data_false = data_prof[data_prof[\"label\"]==False]\n",
    "    if (debug >= 2):\n",
    "        print (\"Data False cases:\", data_false.shape[0])\n",
    "        \n",
    "    train_data_false = data_false[\"tuples\"].tolist()\n",
    "    random.shuffle(train_data_false)\n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples list false:\")\n",
    "        print (train_data_false[:5])  \n",
    "        \n",
    "    # Split text and label of false cases into two lists\n",
    "    texts_false, cats_false = zip(*train_data_false)\n",
    "    if (debug >= 2):\n",
    "        print (\"Texts True cases:\")\n",
    "        print (texts_true[0:5])\n",
    "        print (\"Cats False cases:\")\n",
    "        print (cats_true[0:5])\n",
    "    \n",
    "    # Size of train_data_false and test_data_false\n",
    "    if (limit > 0) & ((len(train_data_false) + len(train_data_true)) * split > limit):\n",
    "        train_split_false = int(limit - len(train_data_true) * split) \n",
    "        test_split_false = int(len(train_data_false) * (1 - split))\n",
    "    else:\n",
    "        train_split_false = int(len(train_data_false) * split)\n",
    "        test_split_false = int(len(train_data_false) * (1 - split))\n",
    "        \n",
    "    if (debug >= 1):\n",
    "        print (\"Train data False:\", train_split_false, \", Test data False: \", test_split_false)   \n",
    "    \n",
    "    \n",
    "    # Mix true and false cases and split in train and devel\n",
    "    # All the true cases are included\n",
    "    train_texts = texts_true[:split_true] + texts_false[:train_split_false]\n",
    "    train_cats = cats_true[:split_true] + cats_false[:train_split_false]\n",
    "    test_texts = texts_true[split_true:] + texts_false[-test_split_false:]\n",
    "    test_cats = cats_true[split_true:] + cats_false[-test_split_false:]\n",
    "    if (debug >= 1):\n",
    "        print (\"Train texts: \", len(train_texts), \", Test texts: \", len(test_texts))\n",
    "        \n",
    "    # Return train data and test data\n",
    "    return (train_texts, train_cats), (test_texts, test_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the level of accuracy using the test set to compare the prediction with the label defined by the user \n",
    "# Obtains the indicators: Precission (p), Recall (r) and F-score (f)\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    fp_list = list()\n",
    "    fn_list = list()\n",
    "    \n",
    "    if (debug == 1):\n",
    "        print (\"EVALUATE\")\n",
    "        \n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "                fp_list.append(doc)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fp: \", doc)\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "                fn_list.append(doc)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fn: \", doc)                \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score, \n",
    "            \"false_positive\": fp_list, \"false_negative\": fn_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the training information, transforms it, trains the model with this set of data, evaluate the result \n",
    "# and saves the resulting model\n",
    "\n",
    "def train_model(model=None, language=\"ca\", target_loss=0.001, n_texts=2000):\n",
    "    \n",
    "    if (debug == 1):\n",
    "        print (\"TRAIN MODEL\")\n",
    "        \n",
    "    # Load the model form spacy\n",
    "    nlp = spacy.load(model)\n",
    "\n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    # add label to text classifier\n",
    "    textcat.add_label(\"POSITIVE\")\n",
    "    textcat.add_label(\"NEGATIVE\")\n",
    "        \n",
    "    # load training and test data\n",
    "    (train_texts, train_cats), (dev_texts, dev_cats) = load_data(n_texts, 0.8, language)\n",
    "\n",
    "    if debug:\n",
    "        print(\n",
    "            \"Using {} examples ({} training, {} evaluation)\".format(\n",
    "                n_texts, len(train_texts), len(dev_texts)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # converts the data to the format:\n",
    "    # (text, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}))\n",
    "    train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "    if debug:\n",
    "        print (\"Train_data: \")\n",
    "        print (train_data[:5])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "#        if init_tok2vec is not None:\n",
    "#            with init_tok2vec.open(\"rb\") as file_:\n",
    "#                textcat.model.tok2vec.from_bytes(file_.read())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Training the model...\")\n",
    "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "        loss = 100\n",
    "        prev_loss = 1000\n",
    "        while (loss > target_loss) | (prev_loss - loss > target_loss):\n",
    "            prev_loss = loss\n",
    "#        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=batch_sizes)\n",
    "            count = 0\n",
    "            for batch in batches:\n",
    "                if (debug >= 2):\n",
    "                    print (\"Batch: \")\n",
    "                    print (batch)\n",
    "                texts, annotations = zip(*batch)\n",
    "                if (count == 0):\n",
    "                    count = 1\n",
    "                    print (texts)\n",
    "\n",
    "                # EliminaciÃ³n del 20% de los casos para evitar generalizaciones\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print(\n",
    "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(  # print a simple table\n",
    "                    losses[\"textcat\"],\n",
    "                    scores[\"textcat_p\"],\n",
    "                    scores[\"textcat_r\"],\n",
    "                    scores[\"textcat_f\"],\n",
    "                )\n",
    "            )  \n",
    "            loss = losses[\"textcat\"]\n",
    "            \n",
    "        print ()\n",
    "        print (\"False positives:\")\n",
    "        print (scores[\"false_positive\"])\n",
    "        print ()\n",
    "        print (\"False negatives\")\n",
    "        print (scores[\"false_negative\"])\n",
    "            \n",
    "    # test the trained model\n",
    "    print (\"\")\n",
    "    print (\"Some examples: \")\n",
    "    test_texts ={\"ca\": [\"Costa que pengi els materials acordats al campus\",\n",
    "                    \"No he tingut aquesta professora\",\n",
    "                    \"No ha impartit classe a aquest grup\",\n",
    "                    \"No ha corregit examens fets a octubre, i estem al mes de gener.\"],\n",
    "            \"es\": [\"No he tenido contacto\", \n",
    "                   \"Muy  buenas clases\",\n",
    "                   \"No nos dio clases\",\n",
    "                   \"No vimos a en clase a este docente\"\n",
    "                   \"No se ha adaptado a la actual situaciÃ³n\"\n",
    "                  ],\n",
    "            \"en\": [\"I haven't had this professor\",\n",
    "                   \"We don't know this person\",\n",
    "                   \"He isn't a good professor\",\n",
    "                   \"We had only a few lessons\"\n",
    "                  ]\n",
    "        }     \n",
    "    for test_text in test_texts[language]:\n",
    "        doc = nlp(test_text)\n",
    "        print(test_text, doc.cats)\n",
    "    print (\"\")\n",
    "    \n",
    "    # Save de model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(pathmodel + language)\n",
    "    print(\"Saved model to\", pathmodel + language)\n",
    "        \n",
    "    # test the saved model\n",
    "    print(\"Loading from\", pathmodel+ language)\n",
    "    nlp2 = spacy.load(pathmodel +  language)\n",
    "    for test_text in test_texts[language]:\n",
    "        doc2 = nlp2(test_text)\n",
    "        print(test_text, doc2.cats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathori = \"../data/original\"\n",
    "pathdest = \"../data/preprocessed/\"\n",
    "pathmodel = \"../data/models/model1/\"\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING LANGUAGE: ca\n",
      "Model: ca_fasttext_wiki\n",
      "TRAIN MODEL\n",
      "LOAD_DATA\n",
      "Original data:  3985\n",
      "Train data True: 59 , Test data True:  15\n",
      "Train data False: 1940 , Test data False:  782\n",
      "Train texts:  1999 , Test texts:  797\n",
      "Using 2000 examples (1999 training, 797 evaluation)\n",
      "Train_data: \n",
      "[('No he tingut a aquest professor', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('No lâhe tingut', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('no LÂ´he tingut', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('NomÃ©s va venir un dia a la sortida de camp. ', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), (\"No l'hem tingut\", {'cats': {'POSITIVE': True, 'NEGATIVE': False}})]\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "(\"Malauradament un cop iniciat el confinament, tot ha estat fum. Ha desaparegut la seva persona. Algun correu ha fet respecte el treball a entregar perÃ² poca cosa. L'examen es basa en lectures eternes que els alumnes hem de preparar de manera autonoma. \", \"Un nivell d'exigencia massa elevat. \", \"Durant les classes online, ha confiat massa en ensenyar-nos el temari mitjanÃ§ant videos. S'agrairia que es tinguessin com a eina apart per ajudar l'alumne a la hora d'estudiar, i que en el moment de fer classe ens ho expliquÃ©s ella mateixa.\", 'Amb la situaciÃ³ del Covid-19, la seva adaptaciÃ³ cap a nosaltres ha estat excel-lent. ')\n",
      "EVALUATE\n",
      "0.931\t0.800\t0.533\t0.640\n",
      "(' El que no pot ser Ã©s que faci una avaluaciÃ³ amb un temps tan limitat. Per molt que tinguis coneixements, no tens opciÃ³ a mostrar-los. Simplement cal observar les notes de la prova. En les quals sol aproven 4 persones i la que te millor nota Ã©s un 6. Ãs VERGONYÃS!\\r', \"Continguts necessaris i interessants perÃ² classes una mica massa magistrals per estar dins un mÃ ster d'innovaciÃ³.\", \"Ha hagut un excÃ©s d'exigÃ¨ncia en quant a les tasques demanades setmanalment i la llargada d'aquestes. Moltes semblaven mÃ©s aviat un treball de l'assignatura que no una prÃ ctica per desenvolupar un tema concret. Fins gairebÃ© el final del semestre no es va modificar la quantitat desmesurada de treball fet que ens ha portat a dedicar menys hores a altres tasques que tenim pendents com el Treball de final de grau. Entenc que no ha estat una situaciÃ³ fÃ cil de gestionar, perÃ² m'agradaria que els alumnes fossim mÃ©s escoltats. \", \"No tinc res a dir, a complert amb el que he respost. L'Ãºnic que poder miraria de que tinguÃ©s les notes de prÃ ctiques amb temps ja que aixÃ­ ens podem guiar si la resta de les que fem anem per bon camÃ­ o no. PerÃ² per la resta tot bÃ©. \", \"Eloi GarÃ­ Ã©s un excelÂ·lent professor. Intenta que els alumnes treguin el mÃ xim de la seva assignatura i ho aconsegueix, a mÃ©s de fer-la interessant. S'ha adaptat molt bÃ© a la situaciÃ³ actual i ens facilita l'estudi i l'aprenentatge.\", \"M'ha agradat molt com explica la assignatura\")\n",
      "EVALUATE\n",
      "0.153\t0.750\t0.600\t0.667\n",
      "(\"El tracte amb l'alumnat Ã©s de superioritat i no permet comentar certs dubtes, quan els planteges en ocasions et fa comentaris innecessaris i fora de lloc.\", \"Durant aquest perÃ­ode de confinament, hem tingut considerables problemes amb aquest professor a causa de no arribar a acords en els quals ambdues parts estiguÃ©ssim satisfetes. Ha ignorat totalment les nostres propostes i opinions i ha decidit dur a terme les accions que ha considerat oportunes, sense ni tan sols valorar si aquestes ens perjudicaven mÃ©s o no en aquesta situaciÃ³ extraordinÃ ria. Entre elles es podria incloure el mÃ¨tode avaluatiu d'examen tipus test via online de 40 preguntes en 15 minuts.\", 'Una dels aspectes a millorar Ã©s la manera com puntua la Laura, ja que Ã©s molt exigent i si et deixes una PARAULA ja descompte punts. \\r\\nPer lo altre, trobo que Ã©s una bona professora i molt atenta dels seus alumnes!!!!!!!!!\\r\\n', \"Hauria d'explicar el temari mÃ©s enllÃ  del que estÃ  escrit en la presentaciÃ³ de classe. A mÃ©s, hauria de portar un ritme mÃ©s calmat durant les explicacions. \", 'Ha estat un professor present des del minut 0 de lâassignatura i ens ha deixat clar tot el que fariem des dâaquell moment, Ã©s una qualitat que valorem molt. ', \"Dir que tot i la situaciÃ³ actual de COVID-19, com a responsable de l'assignatura ha sigut l'Ãºnic professor que ha buscat alternatives per a poder dur un ritme de classe mÃ©s formal i correcte (classes virtuals). Com a aspecte a millorar, el fet de no donar-nos suficients pautes abans de l'examen i que apenes sapiguem el que entra i hem d'estudiar previ a aquest.\", \"Inseguretat a l'hora d'aclarir conceptes, explica conceptes de forma diferent a la resta del professors de l'assignatura, Ã©s necessari mÃ©s ordre a l'hora d'explicar les diapositives.\", \"Igual que amb el Dr. Yuguero, Ã©s difÃ­cil tenir una opiniÃ³ sobre si el Dr. PifarrÃ© compleix amb els horaris o si utilitza mÃ¨todes adequats. De totes maneres, les activitats pertinents a la seva part de l'assignatura personalment em semblen una bona estratÃ¨gia per a preparar als alumnes per a tenir pensament crÃ­tic i formar-se a l'hora de fer exposicions en anglÃ¨s.\")\n",
      "EVALUATE\n",
      "0.229\t0.706\t0.800\t0.750\n",
      "('TÃ© tendÃ¨ncia a la discriminaciÃ³ a certs alumnes de classe, fins i tot aquestes maneres de fer estan relacionades amb un carÃ cter xenÃ²fob.\\r\\n\\r', \"A mÃ©s puntua d'una forma extranya, ja que no especifica el que vol a l'activitat i desprÃ©s les noes sÃ³n baixes.\\r\\nPel que fa a les classes presencials, trobo que Ã©s molt bona professora, ja que busca alternatives i fa les classes molt dinÃ miques, perÃ² amb la situaciÃ³ del COVID-19, les activitats estaven bÃ©, perÃ² la forma d'avaluar massa baixa.\", 'Molt ordenada i responsable. Ãs una tranquilitat fer classes amb ella perquÃ¨ saps que tot ho entendrÃ s bÃ©.', \"A vegades mostra una actitud prepotent e incomoda a l'hora de participar en les classes.\", \"OrganitzaciÃ³ a l'hora de treballar i dinamitzar activitats\\r\\n\", \"Ha tingut una actitud molt bona per l'assignatura, tot i que el temari que es dona, la veritat Ã©s que Ã©s molt,molt teÃ²ric i difÃ­cil de interioritzar\", 'Crec que deuria especificar mÃ©s amb el temari i fer una relaciÃ³ mÃ©s directa entre alumne-professor, ja que crec que Ã©s molt distant.', 'La Maite ha estat una professora molt entregada i se li nota que gaudeix del que ensenya. Sempre ha tingut en compte les nostres peticions, sobretot durant el temps de confinament. ', \"Expluca molt bÃ©, i es un bon professor, pero la dificultat de les proves d'avaluaciÃ³ es massa alta, inclÃºs dins del grau d'enginyeria. \", \"Ãs l'Ãºnic professor que hem tingut que des de el primer moment que va comenÃ§ar la situaciÃ³ del COVID-19 s'ha adaptat a la situaciÃ³ i ens ha fet classe, ha creat sales individuals per cada grup de treball per poder treballar les activitats i ell estar a la sala comuna per si teniem dubtes. Ens ha plantejat un examen adaptat a la situaciÃ³... Ens hem sentit recolÃ§ats per ell i ho valorem molt, sobretot en aquesta situaciÃ³ de incerteÃ§a.\")\n",
      "EVALUATE\n",
      "0.014\t0.706\t0.800\t0.750\n",
      "(\"Donar un resultat en els exercicis serviria per anar treballant millor i no quedarse tan encallat en mig d'un problema per veure si et dona semblant, perÃ² no t'ho dona. \\r\\nEtc, etc.\", 'Juanfran Ã©s un bon profe i si et pot ajudar ho farÃ . Sempre estÃ  obert a noves propostes i aixÃ² fa que potser volguem aprendre mÃ©s.', \"Vaig demanar una revisiÃ³ d'examen i no me la va concedir. \", \"El fet de tindre un examen i fer a soles una classe el dia d'abans i de forma molt rÃ pida crec que no m'ha ajudat a aprendre sobre l'examen, sobre el temari d'aquesta evaluaciÃ³. Hauria de fer mÃ©s classes virtuals per al prÃ²xim examen i baixar el % en el primer examen ja que vam tindre que estudiar eixe examen sense la seua ajuda. \", \"Molt mala organitzaciÃ³ i falta d'explicaciÃ³. Les classes no s'encaren bÃ© i fan que la gent desconecti i no entengui res. \", 'Explica molt bÃ© i ens ha estrucuturat lâassignatura de la millor forma possible. Lâha encarat al nostre Ã mbit i posa exemples dâaixÃ². ', \"La metodologia de les seves classes Ã©s una mica tradicional, perÃ² s'ha adaptat molt bÃ© a les circumstÃ ncies i ens ha facilitat en tot moment la feina alhora que sempre estÃ  disposat a resoldre dubtes, tant per correu de forma rÃ pida i clara com a les videoconferÃ¨ncies. Compleix sempre amb els horaris establerts i transmet la seva passiÃ³ als alumnes, fet que afavoreix la motivaciÃ³ dels alumnes. \", 'En referencia a la professora, Ã©s molt bona comunicadora i pels alumnes que dret no Ã©s el nostre punt fort, les seves explicacions ens han facilitat molt el seguiment de lâassignatura. TambÃ© Ã©s valora el trivial, els tutorials...', \"Remarca molt bÃ© els conceptes per tal de fer-los entendre. AixÃ² ajuda molt a l'estudiant.\", \"Es dels profes que millor ha adaptat l'assignatura al curs tenint en compte els efectes de la pandemia\", \"Degut a les circumstÃ ncies de la Covid-19 prÃ cticament no l'hem conegut, ens ha enviat algun vÃ­deo explicatiu perÃ² poc mÃ©s. S'hauria agraÃ¯t alguna tutoria per videoconferÃ¨ncia pel que fa al desenvolupament del treball en grup.\", \"Penso que vam trigar molt a fer les videoconferÃ¨ncies virtuals per tal d'explicar el temari de l'examen. \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATE\n",
      "0.002\t0.667\t0.800\t0.727\n",
      "(\"A l'hora d'explicar putser dona per suposat informaciÃ³ que en teoria no sabem del tot, i moltes de les seves classes va massa rÃ pid i no dona temps a adquirir les idees sobre el que estÃ  explicant.\", 'Un bon professor. ', 'No ha estat el meu tutor, no puc avaluar-lo.', \"Estic molt contenta amb ambdues professores. han sigut molt empÃ tiques en aquesta situaciÃ³ tant difÃ­cil, i ens han facilitat un munt les eines per a poder continuar amb l'assignatura\", 'Molt correcte', \"Ha tingut una actitud molt bona per l'assignatura, tot i que el temari que es dona, la veritat Ã©s que Ã©s molt,molt teÃ²ric i difÃ­cil de interioritzar\", \"En les classes ja Ã©s un professor que no explica bÃ© i que ens deixa molta llibertat als alumnes, que aixÃ² Ãºltim en certa manera ja estÃ  bÃ©. El problema mÃ©s gran ha estat durant el confinament: ens ha deixat bastant de banda, se'ns ha dit que Ã©s per la quantitat de feina que tenia, sobretot amb altres assignatures. Segur que es veritat. Potser no se'n haurien de donar tantes.\", 'Al principi estava molt tensa amb nosaltres, perÃ² ens vam anar coneixent i finalment va ser molt molt comprensiva amb nosaltres. \\r\\nNo tinc res dolent a dir sobre ella, al contrari. ', 'No ha fet cap classe online. ', 'La Judit Ã©s una professora excelent! Ãs atenta, amable, respectuosa i molt propera. Hauriem de poder tindre mÃ©s professores com ella', ' Estic molt disgustat amb aquesta asignatura i sobretot amb la professora. Les seves classes no les entÃ©n ni ella, no segueix cap contingut i fa fer activitats sense sentit. ', 'ell amb tot el morro va dir: \"la resta de grups que heu entes?', 'Bona docÃ¨ncia presencial. ', 'Es una bona professora, explica molt bÃ© els continguts, clarament i amb imatges grÃ fiques. GrÃ cies a ella aprenem en la part de dietoterapia.')\n",
      "EVALUATE\n",
      "0.001\t0.667\t0.800\t0.727\n",
      "('El molt bona professora i la Luisa tambÃ©. Molt properes. Es nota que en saben molt i que els hi agrad ensenyar.', \"No tinc cap queixa al respecte, perÃ² hauria d'innovar els seus recursos i viure una mica mÃ©s de prop la docÃ¨ncia. Sap molt perÃ² no sap transmetre els coneixements, i tampoc tÃ© gaire ganes de fer-ho. A mÃ©s, tampoc Ã©s gaire flexible a l'hora de millorar la situaciÃ³ dels alumnes. Porta fent els mateixos exÃ mens 40 anys.\", \"El Roger ens ha enviat el text del temario que hauria explicat a classe, a mÃ©s d'algÃºn vÃ­deo explicatiu i els powers. TambÃ© ha contestant rÃ pidament quan li hem preguntar alguna cosa i ha accedit a moure la data de l'examen final per tal d'ajudar-nos, ja que la situaciÃ³n en la que ens trobem no Ã©s gens fÃ¡cil.\", \"Dir que tot i la situaciÃ³ actual de COVID-19, com a responsable de l'assignatura ha sigut l'Ãºnic professor que ha buscat alternatives per a poder dur un ritme de classe mÃ©s formal i correcte (classes virtuals). Com a aspecte a millorar, el fet de no donar-nos suficients pautes abans de l'examen i que apenes sapiguem el que entra i hem d'estudiar previ a aquest.\", 'El sistema de sessions grabades i consultes durant la setmana, Ã©s un molt bon sistema per seguir les classes durant el confinament.', 'NomÃ©s llegeix els apunts que tenim, la qual cosa, anar a classe o no Ã©s el mateix', 'Actitud pessima. Llegeix i rellegeix el pwp. No sento que aprengui res. Lectures innecessÃ ries. ', \"Considero que ha estat un bon professor ja que s'ha adaptat en tot moment a les situacions que ens hem trobat, ens ha donat molts recursos  per a treballar l'assginatura i l'aprenentatge ha estat tant prÃ ctic com teÃ²ric (considero que Ã©s un aspecte fonamental).  Crec que la seva actuaciÃ³ ha estat excelÂ·lent.  \", \"Personalment trobo que el mÃ¨tode d'ensenyament i avaluaciÃ³ de la part impartida pel professor Colinas no resulta efectiu. Penso que, malgrat l'esforÃ§ que fa el professor per adaptar el mÃ¨tode d'ensenyament a l'actualitat, no s'aconsegueix transmetre els coneixements, i l'aprenentatge per part de l'alumnat Ã©s molt poc. A mÃ©s, el mÃ¨tode d'avaluaciÃ³ dÃ³na peu a la confrontaciÃ³ entre alumnes degut a la competitivitat que suposa, i la forma amb quÃ¨ es corregeixen les activitats sovint Ã©s molt arbitrÃ ria i poc fonamentada. \\r\\nL'actitud cap a l'alumne hauria de ser mÃ©s respectuosa.\\r\\nCrec que el professor Carlos Colinas Ã©s una persona mÃ©s que capacitada per realitzar una gran tasca docent i crec que es pot aprendre molt d'ell, perÃ² sens dubte, aquest no Ã©s el mÃ¨tode idoni per fer-ho i convÃ© un canvi urgent en la metodologia d'aquesta part de l'assignatura.\", 'Degut al COVID-19, no hem pogut trobar-nos ni realitzar classes', \"Molt coherent. M'ha agradat molt com a professor, n'he aprÃ¨s molt.\\r\\n\", \" buscar una notÃ­cia de premsa sobre algun patÃ²gen. AquÃ­ la majoria tenim un 0 per motius com que hem copiat, cosa que no entenem de qui devem haver copiat...o perquÃ¨ resulta que no Ã©s un patÃ²gen, cosa d'esperar ja que encara no ens ha explicat absolutament res de patÃ²gens i no sabem diferenciar-los ni res. O per altres motius absurds. Directament un 0 rodÃ³.\\r\\n\", \"Degut a l'estat d'emergÃ¨ncia sanitÃ ria, no hem pogut assisstir a les seves classes, perÃ² ens ha donat el material necessari per assolir els continguts de manera telemÃ tica. Tanmateix, personalment m'haguÃ©s agradat que es poguessin continuar fent les classes online mitjanÃ§ant la videotrucada. \", \"Vaig demanar una revisiÃ³ d'examen i no me la va concedir. \", \"El professor que Ã©s mÃ©s proper als alumnes i que s'interessa mÃ©s per els problemes que pots tenir. Et tracta com un mÃ©s i no amb la superioritat de ser professor i saberho tot. Sense cap mena de dubte el millor professor de tota l'assignatura. MÃ©s professors com ell siusplau\", \"La Clara Ã©s una crack! M'ha agradat molt la manera en que ens ha presentat la histÃ²ria i els recursos que ens ha facilitat per treballar-la amb els nens i nenes. TÃ© molts coneixments i transmetre'ls!\")\n",
      "EVALUATE\n",
      "0.000\t0.750\t0.800\t0.774\n",
      "\n",
      "False positives:\n",
      "[No lâhem tingut, No l'hem tingut a aquesta persona (Karen), hem tingut al Marc a histÃ²ria, NomÃ©s vam tenir-la un dia, No compleix les seves funcions com a coordinadora de MÃ ster.]\n",
      "\n",
      "False negatives\n",
      "[No la tinc, No en tinc ni la mÃ©s remota idea de qui Ã©s vostÃ¨, perÃ² se li ha de reconÃ¨ixer que ara per ara Ã©s el que mÃ©s sentit comÃº ha mostrat al no manar-nos seminaris absurds ni fer-nos perdre el temps amb informaciÃ³ obvia en power points. Moltes grÃ cies., Degut a la situaciÃ³ d'emergencia no he tingut el plaer de gaudier de les clases de la profesora, aixÃ­ que no puc fer una valoraciÃ³ amb criteri ]\n",
      "\n",
      "Some examples: \n",
      "Costa que pengi els materials acordats al campus {'POSITIVE': 4.34029152529547e-06, 'NEGATIVE': 0.9999957084655762}\n",
      "No he tingut aquesta professora {'POSITIVE': 0.9999886751174927, 'NEGATIVE': 1.1268468369962648e-05}\n",
      "No ha impartit classe a aquest grup {'POSITIVE': 0.9948862195014954, 'NEGATIVE': 0.005113802384585142}\n",
      "No ha corregit examens fets a octubre, i estem al mes de gener. {'POSITIVE': 1.626603989279829e-05, 'NEGATIVE': 0.9999837875366211}\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/model1/ca'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-70948a4cff9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAINING LANGUAGE: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Model: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-05e7ff12144d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, language, target_loss, n_texts)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Save de model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathmodel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mto_disk\u001b[0;34m(self, path, exclude, disable)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mto_disk\u001b[0;34m(path, writers, exclude)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwriters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/model1/ca'"
     ]
    }
   ],
   "source": [
    "n_iter = 5\n",
    "target_loss = 0.001\n",
    "n_texts = 2000\n",
    "languages = {\"ca\":\"ca_fasttext_wiki\", \"es\":\"es_core_news_sm\", \"en\":\"en_core_web_sm\" }\n",
    "#languages = {\"ca\":\"ca_fasttext_wiki\"}\n",
    "\n",
    "for language in languages:\n",
    "    model = languages[language]\n",
    "    \n",
    "    print()\n",
    "    print (\"TRAINING LANGUAGE: \" + language)    \n",
    "    print (\"Model: \" + model)\n",
    "    train_model (model, language, target_loss, n_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
