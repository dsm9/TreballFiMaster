{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Tipus incidència 'Comentari problemàtic'\n",
    "\n",
    "This notebook creates a evaluates a model to detect the issue 'Comentari problemàtic'.\n",
    "\n",
    "It will be created a model to each language: catalan, spanish and english.\n",
    "\n",
    "This type of issue is characterized by long coments composed for some sentences and imprecisse expressions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load(\"ca_fasttext_wiki\")\n",
    "#nlp = spacy.load(\"es_core_news_sm\")\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates tuples with texts and cats in the whole comment\n",
    "\n",
    "def create_texts_and_cats_comments(data_com, nlp):\n",
    "    \n",
    "    # Converts data frame to list\n",
    "    #data_com = data_com.dropna(subset=\"Comentari\")\n",
    "    data_com = data_com[data_com[\"Comentari\"].notnull()]\n",
    "    data_list = data_com[\"tuples\"].tolist()\n",
    "    \n",
    "    # Change order of comments\n",
    "    random.shuffle(data_list)\n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples list:\")\n",
    "        print (data_list[:5])  \n",
    "        \n",
    "    # Split text and label of true cases into two lists\n",
    "    texts, cats = zip(*data_list)\n",
    "    if (debug >= 2):\n",
    "        print (\"Texts:\")\n",
    "        print (texts[0:5])\n",
    "        print (\"Cats:\")\n",
    "        print (cats[0:5])  \n",
    "\n",
    "    return (texts, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates tuples with texts and cats, spliting sentences in the comment\n",
    "\n",
    "def create_texts_and_cats_sentences(data_com, nlp):\n",
    "    \n",
    "    # Split comments in sentences\n",
    "    data_com = data_com[data_com[\"Comentari\"].notnull()]\n",
    "    train_data = data_com[\"tuples\"].tolist()\n",
    "    train_list = []\n",
    "    for row in train_data:\n",
    "        comment = row[0]\n",
    "        label = row[1]\n",
    "        doc = nlp(comment)\n",
    "        for sent in doc.sents:\n",
    "            train_list.append((sent.text, label))\n",
    "            if ((debug >=2) and (len(train_list)<=10)):\n",
    "                print(\"+ \", sent)\n",
    "                print(\"  \", label)\n",
    " \n",
    "    if (debug >= 1):\n",
    "        print(\"Sentences: \", len(train_list))\n",
    "\n",
    "    # Change order of comments\n",
    "    random.shuffle(train_list)\n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples list:\")\n",
    "        print (train_list[:5])  \n",
    "        \n",
    "     # Split text and label of true cases into two lists\n",
    "    texts, cats = zip(*train_list)\n",
    "    if (debug >= 2):\n",
    "        print (\"Texts:\")\n",
    "        print (texts[0:5])\n",
    "        print (\"Cats:\")\n",
    "        print (cats[0:5])   \n",
    "        \n",
    "    return (texts, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads information from preprocessed file to create de train and test data\n",
    "\n",
    "def load_data(limit = 0, split = 0.8, language = \"es\", nlp = None):\n",
    "\n",
    "    if (debug >= 1):\n",
    "        print (\"LOAD_DATA\")\n",
    "        print (\"Language: \", language)\n",
    "        \n",
    "    # Load the model form spacy\n",
    "#    nlp = spacy.load(model)\n",
    "#    if (debug >= 1):\n",
    "#        print (\"Model loaded: \", model)\n",
    "    \n",
    "    # Load data from file\n",
    "    file = \"comentaris_\" + language + \".csv\"\n",
    "    data = pd.read_csv(pathdest + file)\n",
    "    if (debug >= 1):\n",
    "        print(\"Original data: \", data.shape[0])\n",
    "        \n",
    "    if (debug >= 2):\n",
    "        print (\"Sample:\")\n",
    "        display (data.sample(5))\n",
    "\n",
    "    # Calculates label    \n",
    "    data_com = data[[\"Comentari\",\"TipusIncidencia\"]]    # CHANGED\n",
    "    if (debug >= 2):\n",
    "        print (\"Filtered columns:\")\n",
    "        display (data_com.sample(5))    \n",
    "\n",
    "    # Calculates tuples row\n",
    "    # Converts: label=True -> {\"POSITIVE\": True, \"NEGATIVE\": False}\n",
    "    # label=False -> {\"POSITIVE\": False, \"NEGATIVE\": True}\n",
    "    data_com[\"label\"] = data_com[\"TipusIncidencia\"] == \"Comentari problemàtic\"  # CHANGED\n",
    "    data_com[\"tuples\"] = data_com.apply(lambda row: (row[\"Comentari\"], {\"POSITIVE\": bool(row[\"label\"]), \"NEGATIVE\": not bool(row[\"label\"])}), axis=1)    \n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples dataframe:\")\n",
    "        display (data_com.sample(5))\n",
    "\n",
    "    # Create texts and cats lists for true cases\n",
    "    data_true = data_com[data_com[\"label\"]==True]\n",
    "    if (debug >= 1):\n",
    "        print (\"True comments: \", data_true.shape[0])\n",
    "        \n",
    "    (texts_true, cats_true) = create_texts_and_cats_comments(data_true, nlp)\n",
    "    #(texts_true, cats_true) = create_texts_and_cats_sentences(data_true, nlp)\n",
    "    if (debug >= 2):\n",
    "        print(\"Texts:\",len(texts_true), \"Cats:\", len(cats_true))\n",
    "        \n",
    "    # Size of train_data_true and test_data_true\n",
    "    split_true = int(len(texts_true) * split)+1\n",
    "    if (debug >= 1):\n",
    "        print (\"Train True data:\", split_true, \", Test True data: \", len(texts_true)-split_true)      \n",
    "                \n",
    "    # Create texts and cats lists for false cases        \n",
    "    data_false = data_com[data_com[\"label\"]==False]\n",
    "    if (debug >= 1):\n",
    "        print (\"False comments:\", data_false.shape[0])\n",
    "\n",
    "    (texts_false, cats_false) = create_texts_and_cats_comments(data_false, nlp)\n",
    "    #(texts_false, cats_false) = create_texts_and_cats_sentences(data_false, nlp)\n",
    "    if (debug >= 2):\n",
    "        print(\"Texts:\",len(texts_false), \"Cats:\", len(cats_false))        \n",
    "       \n",
    "    # Size of train_data and test_data, considering limit\n",
    "    if (limit > len(texts_true) + len(texts_false)):\n",
    "        limit = len(texts_true) + len(texts_false)\n",
    "    split_total = int(limit * split)\n",
    "\n",
    "    if (debug >= 1):\n",
    "        print (\"Used data:\", limit)\n",
    "        print (\"Train data: \", split_total, \", Test data: \", limit - split_total)\n",
    "         \n",
    "    # Size of train_data_false and test_data_false\n",
    "    train_split_false = split_total - split_true\n",
    "    test_split_false = (limit - split_total) - (len(texts_true) - split_true) \n",
    "        \n",
    "    if (debug >= 1):\n",
    "        print (\"Used False comments: \", limit - len(texts_true))\n",
    "        print (\"Train False data: \", train_split_false, \", Test False data: \", test_split_false)  \n",
    "        \n",
    "         \n",
    "    # Mix true and false cases and split in train and devel\n",
    "    # All the true cases are included\n",
    "    train_texts = texts_true[:split_true] + texts_false[:train_split_false]\n",
    "    train_cats = cats_true[:split_true] + cats_false[:train_split_false]\n",
    "    test_texts = texts_true[split_true:] + texts_false[-test_split_false:]\n",
    "    test_cats = cats_true[split_true:] + cats_false[-test_split_false:]\n",
    "        \n",
    "    # Return train data and test data\n",
    "    return (train_texts, train_cats), (test_texts, test_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the level of accuracy using the test set to compare the prediction with the label defined by the user \n",
    "# Obtains the indicators: Precission (p), Recall (r) and F-score (f)\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    fp_list = list()\n",
    "    fn_list = list()\n",
    "    \n",
    "    if (debug == 2):\n",
    "        print (\"EVALUATE\")\n",
    "        \n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "                if (debug >= 2):\n",
    "                    print (\"tp: \", doc)\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "                fp_list.append(doc)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fp: \", doc)\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "                if (debug >= 2):\n",
    "                    print (\"tn: \", doc)\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "                fn_list.append(doc)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fn: \", doc)   \n",
    "    if (debug >= 2):\n",
    "        print(\"tp: \", tp, \", fp: \", fp, \", tn: \", tn, \", fn: \", fn)\n",
    "        \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score, \n",
    "            \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn,\n",
    "            \"fp_list\": fp_list, \"fn_list\": fn_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the training information, transforms it, trains the model with this set of data, evaluate the result \n",
    "# and saves the resulting model\n",
    "\n",
    "def train_model(model=None, language=\"ca\", target_loss=0.001, n_texts=2000):\n",
    "    if (debug >= 1):\n",
    "        print (\"TRAIN MODEL\")\n",
    "        \n",
    "    # Load the model form spacy\n",
    "    nlp = spacy.load(model)\n",
    "    if (debug >= 1):\n",
    "        print (\"Model loaded: \", model)\n",
    "        \n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    # add label to text classifier\n",
    "    textcat.add_label(\"POSITIVE\")\n",
    "    textcat.add_label(\"NEGATIVE\")\n",
    "    \n",
    "    if \"sentencizer\" not in nlp.pipe_names:\n",
    "        nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "        \n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\",\"sentencizer\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "#        if init_tok2vec is not None:\n",
    "#            with init_tok2vec.open(\"rb\") as file_:\n",
    "#                textcat.model.tok2vec.from_bytes(file_.read())        \n",
    "        \n",
    "        if (debug >= 1):\n",
    "            print (\"Pipes prepared\")\n",
    "        \n",
    "        # load training and test data\n",
    "        (train_texts, train_cats), (dev_texts, dev_cats) = load_data(n_texts, 0.8, language, nlp)        \n",
    "\n",
    "        if (debug >= 1):\n",
    "            print(\n",
    "                \"Using {} examples ({} training, {} evaluation)\".format(\n",
    "                    len(train_texts)+len(dev_texts), len(train_texts), len(dev_texts)\n",
    "                )\n",
    "            )      \n",
    "\n",
    "        # converts the data to the format:\n",
    "        # (text, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}))\n",
    "        train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "        if (debug>=1):\n",
    "            print (\"Train_data: \")\n",
    "            print (train_data[:5])        \n",
    "    \n",
    "        # Train the model\n",
    "        print(\"Training the model...\")\n",
    "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\n",
    "            \"ITER\", \"LOSS\", \"P\", \"R\", \"F\",\"TP\",\"FP\",\"FN\",\"TN\"))\n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "        loss = 100\n",
    "        prev_loss = 1000\n",
    "        iter = 1\n",
    "#        if (loss > target_loss):\n",
    "        while ((loss > target_loss) | (prev_loss - loss > target_loss)) & (iter <= 20):\n",
    "            prev_loss = loss\n",
    "    #        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=batch_sizes)\n",
    "\n",
    "#            if True:\n",
    "#                batch = next(batches)\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                if (debug >= 2):\n",
    "                    print (\"Batch: \", len(batch))\n",
    "                    print (batch)\n",
    "\n",
    "                # Train the model discarting 20% of cases to avoid generalization\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "                if (debug >= 2):\n",
    "                    print (\"Model updated\")\n",
    "\n",
    "            # Evaluates model and print results\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print(\n",
    "                \"{0:.0f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}\\t {5:.0f}\\t {6:.0f}\\t {7:.0f}\\t {8:.0f}\".format(  # print a simple table\n",
    "                    iter,\n",
    "                    losses[\"textcat\"],\n",
    "                    scores[\"textcat_p\"],\n",
    "                    scores[\"textcat_r\"],\n",
    "                    scores[\"textcat_f\"],\n",
    "                    scores[\"tp\"],\n",
    "                    scores[\"fp\"],\n",
    "                    scores[\"fn\"],\n",
    "                    scores[\"tn\"]\n",
    "                )\n",
    "            )  \n",
    "            loss = losses[\"textcat\"]\n",
    "            iter = iter + 1\n",
    "            \n",
    "        print(\"False positives:\")\n",
    "        display(scores[\"fp_list\"][:10])\n",
    "        print(\"False negatives:\")\n",
    "        display(scores[\"fn_list\"][:5])\n",
    "        \n",
    "        print(\"Model trained\")    \n",
    "    \n",
    "    # test the trained model\n",
    "    print (\"\")\n",
    "    print (\"Some examples: \")\n",
    "    test_texts ={\"ca\": [\"Costa que pengi els materials acordats al campus\",\n",
    "                    \"No he tingut aquesta professora\",\n",
    "                    \"Sembla que tingui ganes de que patim, i ens tracta de tontos\",\n",
    "                    \"No ha corregit examens fets a octubre, i estem al mes de gener.\",\n",
    "                    \"No acabem d'entendre què és el que vol, però sembla que no va amb ella el tema\"],\n",
    "            \"es\": [\"No he aprendido nada en ninguna de sus clases, ni siquiera he encontrado herramientas para buscarme la vida.\", \n",
    "                   \"Fue una de las maestras más sensatas y preocupadas por los estudiantes\",\n",
    "                   \"Considero que no debería de seguir siendo profesor del inefc, puesto que ni tiene conocimientos ni ganas.\",\n",
    "                   \"Hace que los alumnos vayan con muchas ganas a sus clases\"\n",
    "                   \"Habla mal a los alumnos y se reprime a los que se quejan\"\n",
    "                  ],\n",
    "            \"en\": [\"I haven't had this professor\",\n",
    "                   \"We don't know this person\",\n",
    "                   \"He isn't a good professor\",\n",
    "                   \"We had only a few lessons\"\n",
    "                  ]\n",
    "        }     \n",
    "    for test_text in test_texts[language]:\n",
    "        doc = nlp(test_text)\n",
    "        print(test_text, doc.cats)\n",
    "    print (\"\")\n",
    "    \n",
    "    # Save de model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(pathmodel + language)\n",
    "    print(\"Saved model to\", pathmodel + language)\n",
    "        \n",
    "    # test the saved model\n",
    "    print(\"Loading from\", pathmodel+ language)\n",
    "    nlp2 = spacy.load(pathmodel +  language)\n",
    "    for test_text in test_texts[language]:\n",
    "        doc2 = nlp2(test_text)\n",
    "        print(test_text, doc2.cats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathori = \"../data/original\"\n",
    "pathdest = \"../data/preprocessed/\"\n",
    "pathmodel = \"../data/models/model2/\"\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN MODEL\n",
      "Model loaded:  ca_fasttext_wiki\n",
      "Pipes prepared\n",
      "LOAD_DATA\n",
      "Language:  ca\n",
      "Original data:  6975\n",
      "True comments:  387\n",
      "Train True data: 310 , Test True data:  77\n",
      "False comments: 6588\n",
      "Used data: 700\n",
      "Train data:  560 , Test data:  140\n",
      "Used False comments:  313\n",
      "Train False data:  250 , Test False data:  63\n",
      "Using 700 examples (560 training, 140 evaluation)\n",
      "Train_data: \n",
      "[(\"L'assignatura ja és avorrida, però a sobre la professora no ajuda. En tots els meus anys acadèmics, que no han estat pocs, mai havia trobat una persona tan desagradable i amb tantes poques ganes de crear una bona atmosfera. Sembla que no li agradi gens la seva feina. La meva prosposta cap a anys vinents és canviar la professora. Em sap molt greu però no hi ha res positiu.\", {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('Tot i això, de vegades pot semblar autoritaria. \\n', {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), (\" no explicar cap contingut no és ensenyar. No ha fet cap classe per explicar continguts, només per resoldre dubtes de les lectures. Encara així ha decidit pujar el % de l'examen al 50%, sense explicar continguts.\\n\", {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), (\"La professora ha estat absent en tota l'assignatura, no ens ha fet un retorn de les avaluacions, sols d'una nota final sense cap comentari de les diferents activitats. _x005F_x000D_\\nA més, ens ha passat un excel amb la nota i els noms i DNI's de totes les persones que participaven a l'assignatura i això clarament vulnera la Llei de protecció de dades. _x005F_x000D_\\nConsidero que la manera com s'ha dut a terme aquesta assignatura és totalment inadequadael nivell no és el d'una classe de màster. \", {'cats': {'POSITIVE': True, 'NEGATIVE': False}}), ('Crec que està bé que és digui el perquè de les notes, però no fa falta atacar a ningú o només dir les coses que estan malament. Fa sentir malalment a les persones. ', {'cats': {'POSITIVE': True, 'NEGATIVE': False}})]\n",
      "Training the model...\n",
      "ITER \tLOSS \t  P  \t  R  \t  F  \t TP  \t FP  \t FN  \t TN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6b79bd23b264>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_com[\"label\"] = data_com[\"TipusIncidencia\"] == \"Comentari problemàtic\"  # CHANGED\n",
      "<ipython-input-6-6b79bd23b264>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_com[\"tuples\"] = data_com.apply(lambda row: (row[\"Comentari\"], {\"POSITIVE\": bool(row[\"label\"]), \"NEGATIVE\": not bool(row[\"label\"])}), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t4.050\t0.789\t0.727\t0.757\t 56\t 15\t 21\t 48\n",
      "2\t1.754\t0.775\t0.805\t0.790\t 62\t 18\t 15\t 45\n",
      "3\t0.499\t0.779\t0.779\t0.779\t 60\t 17\t 17\t 46\n",
      "4\t0.140\t0.769\t0.779\t0.774\t 60\t 18\t 17\t 45\n",
      "5\t0.038\t0.760\t0.740\t0.750\t 57\t 18\t 20\t 45\n",
      "6\t0.004\t0.734\t0.753\t0.744\t 58\t 21\t 19\t 42\n",
      "7\t0.002\t0.744\t0.753\t0.748\t 58\t 20\t 19\t 43\n",
      "8\t0.000\t0.744\t0.753\t0.748\t 58\t 20\t 19\t 43\n",
      "9\t0.000\t0.744\t0.753\t0.748\t 58\t 20\t 19\t 43\n",
      "False positives:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[És un professor que sap mentenir les diferències d'alumne-professor, però que es posa molt en la nostre pell i ens ajuda tant com pugui. Explica molt bé, sense enrollar-se, amb exemples, pausadament, etc. M'agrada molt com ensenya ,\n",
       " Bastant passota.,\n",
       " Com a aquest professor sí que li vam tenir presencialment, el seu mètode d'explicació és excel·lent, sembla més una classe animada en la qual es pot parlar com en una conversa amb un cafè que una classe en la qual tots els alumnes estan mirant l'hora per a anar-se a casa.,\n",
       " Durant les classes presencials estaven les dues professores a classe i era molt fàcil conntactar amb elles i parlar-hi. Però quan vam tancar-nos en quarenetna la cosa va canviar, i al no poder comunicar-se amb facilitat entre elles, nosaltres no hem rebut molt feedback ni masses notícies d'elles...,\n",
       " Les seves respostes són ambigües i no resolen els dubtes dels alumnes.\n",
       " A més, als examens entren continguts que no s'han impartit a classe.,\n",
       " Potser es degut al Covid, però crec que no ha enfocat els temes de jocs de manera correcte, vam estar dues setmanes sense saber que fariem, ens van cambiar el guió d'entrega final de jocs, 3 cops, i feiem coses sense saber realment per que valien la pena.,\n",
       " M'esperava tractar teoria i estudis de gènere, i no només ensenyar un catàleg de dones artistes i les obres que van fer a la seva època, sense cap pretext previ que no sigui repetir coses que ja sabíem.\n",
       " ,\n",
       " Entenc que no es tingui temps de donar tota l'assignatura per tema d'hores (que s'han vist tallades per vagues) però penso que si part de l'assignatura s'imparteix fora del horari que toca, no s'hauria d'evaluar ja que és possible que algú no hi pugui assistir per motius personals.\n",
       " \n",
       " També una altra cosa que m'ha molestat és que encara tenim unes classes pendents (machine learning). El professor ens va enviar un correu dient-nos que ja les fariem per que gent del grau també estava interessada. ¿? \n",
       " \n",
       " És a dir, que jo que he pagat l'assignatura m'he de fer quadrar l'horari en funció de gent que no ha pagat ni un cèntim. I que jo sapigui en cap moment s'ha preguntat si ens va bé o si ens importa que no s'imparteixin aquestes classes fins que es posi d'acord en l'horari amb unes persones que no han pagat res per accedir als mateixos ensenyaments (A dia 20 de febrer encara no hi ha noticies d'aquestes classes). \n",
       " \n",
       " Tot això a mi lo que m'assembla és una presa de pel.,\n",
       " - Durant la dura situació del confinament que no els pots anar a veure al despatx, han ignorat correus que se'ls hi han enviat demanant aclaracions importants sobre l'assignatura o els treballs a realitzar, fet que considero una manca de professionalitat per part seva i fins hi tot ho trobo de mala educació, donat que contestar un correu no suposa un gran esforç i forma part de les seves funcions.,\n",
       " No ha resultat fàcil contactar amb ella tot i que jo perquè no volgués sino perque no se li va facilitar l'accés al campus fins molt avançat el curs]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[l'avaluació va  ser molt ajutada de temps. ,\n",
       " Vaig dur a terme una queixa al professor i més endavant se'm va recriminar el haver dut a terme aquesta queixa. Crec que aquest fet és greu, ja que com he comentat anteriorment, estic en tot el meu dret de fer-ho.,\n",
       " De vegades té un caràcter una mica fort, però explica molt bé i es nota que li agrada l'assignatura,\n",
       " No especifica com hem de realitzar els treballs. Tots hem anat molt perduts i l'ajuda a sigut poca per part d'ell. Penso que ens hauria de contestar mes adequadament els nostres dubtes per saber com i que hem de fer en l'assignatura. ,\n",
       " Considero que el bloc dhomeopatia, fitoteràpia i aromaterapia no haurien de ser continguts evaluables.]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n",
      "\n",
      "Some examples: \n",
      "Costa que pengi els materials acordats al campus {'POSITIVE': 0.001989922719076276, 'NEGATIVE': 0.9980100989341736}\n",
      "No he tingut aquesta professora {'POSITIVE': 4.099362058695988e-07, 'NEGATIVE': 0.9999996423721313}\n",
      "Sembla que tingui ganes de que patim, i ens tracta de tontos {'POSITIVE': 0.9999703168869019, 'NEGATIVE': 2.9632559744641185e-05}\n",
      "No ha corregit examens fets a octubre, i estem al mes de gener. {'POSITIVE': 0.006962038576602936, 'NEGATIVE': 0.9930379986763}\n",
      "No acabem d'entendre què és el que vol, però sembla que no va amb ella el tema {'POSITIVE': 0.6562121510505676, 'NEGATIVE': 0.3437878489494324}\n",
      "\n",
      "Saved model to ../data/models/model2/ca\n",
      "Loading from ../data/models/model2/ca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'ca_fasttext_wiki' (0.0.2) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costa que pengi els materials acordats al campus {'POSITIVE': 0.0011003944091498852, 'NEGATIVE': 0.9988995790481567}\n",
      "No he tingut aquesta professora {'POSITIVE': 1.2194059308967553e-06, 'NEGATIVE': 0.9999988079071045}\n",
      "Sembla que tingui ganes de que patim, i ens tracta de tontos {'POSITIVE': 0.9999798536300659, 'NEGATIVE': 2.0157107428531162e-05}\n",
      "No ha corregit examens fets a octubre, i estem al mes de gener. {'POSITIVE': 0.009615711867809296, 'NEGATIVE': 0.9903842210769653}\n",
      "No acabem d'entendre què és el que vol, però sembla que no va amb ella el tema {'POSITIVE': 0.7937415242195129, 'NEGATIVE': 0.20625843107700348}\n"
     ]
    }
   ],
   "source": [
    "debug = 1\n",
    "target_loss = 0.001\n",
    "n_texts = 700\n",
    "#languages = {\"ca\":\"ca_fasttext_wiki\", \"es\":\"es_core_news_sm\", \"en\":\"en_core_web_sm\" }\n",
    "#languages = {\"ca\":\"ca_fasttext_wiki_lg\", \"es\":\"es_core_news_lg\", \"en\":\"en_core_web_sm\" }\n",
    "languages = {\"ca\":\"ca_fasttext_wiki\"}\n",
    "\n",
    "for language in languages:\n",
    "    model = languages[language]\n",
    "    \n",
    "    print()\n",
    "    #print (\"TRAINING LANGUAGE: \" + language)    \n",
    "    #print (\"Model: \" + model)\n",
    "    train_model (model, language, target_loss, n_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test load_data function\n",
    "debug = 2\n",
    "n_texts = 2000\n",
    "language = \"ca\"\n",
    "model = \"ca_fasttext_wiki\"\n",
    "\n",
    "# Load the model form spacy\n",
    "nlp = spacy.load(model)\n",
    "if (debug >= 1):\n",
    "    print (\"Model loaded: \", model)\n",
    "\n",
    "# load training and test data\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(n_texts, 0.8, language, nlp)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
