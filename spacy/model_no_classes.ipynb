{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model incidència 'No ha impartit classe a aquest grup'\n",
    "\n",
    "This notebook creates a evaluates a model to detect the issue 'No ha impartit classe a aquest grup'.\n",
    "\n",
    "It will be created a model to each language: catalan, spanish and english.\n",
    "\n",
    "Only are treated comments of type 'P : Professor'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load(\"ca_fasttext_wiki\")\n",
    "#nlp = spacy.load(\"es_core_news_sm\")\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads information from preprocessed file to create de train and test data\n",
    "\n",
    "def load_data(limit = 0, split = 0.8, language = \"ca\"):\n",
    "\n",
    "    if (debug >= 1):\n",
    "        print (\"LOAD_DATA\")\n",
    "        \n",
    "    # Load data from file\n",
    "    file = \"comentaris_\" + language + \".csv\"\n",
    "    data = pd.read_csv(pathdest + file)\n",
    "    if (debug >= 2):\n",
    "        print (\"Original data:\")\n",
    "        display (data.sample(5))\n",
    "\n",
    "    # Calculates label and filter rows to be used    \n",
    "    data[\"label\"] = data[\"TipusIncidencia\"] == \"No ha impartit classe a aquest grup\"\n",
    "\n",
    "    data_prof = data[data.TipusPregunta == \"P\"][[\"Comentari\",\"label\"]]\n",
    "    if (debug >= 2):\n",
    "        print (\"Filtered data:\")\n",
    "        display (data_prof.sample(5))\n",
    "\n",
    "    if (debug >= 2):\n",
    "        print (\"Comment of this issue type:\")\n",
    "        display(data_prof[data_prof[\"label\"]].sample(5))\n",
    "\n",
    "    # Converts dataframe into list\n",
    "    data_prof[\"tuples\"] = data_prof.apply(lambda row: (row[\"Comentari\"], row[\"label\"]), axis=1)\n",
    "    train_data = data_prof[\"tuples\"].tolist()   \n",
    "    if (debug >= 2):\n",
    "        print (\"Tuples:\")\n",
    "        print (train_data[:5])    \n",
    "\n",
    "    # Takes an aleatori set of tuples\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    if (debug >= 2):\n",
    "        print (\"Shuffled tuples:\")\n",
    "        print (train_data[:5])    \n",
    "\n",
    "    # Split text and label into two lists\n",
    "    texts, labels = zip(*train_data)\n",
    "    if (debug >= 1):\n",
    "        print (\"Texts:\")\n",
    "        print (texts[0:5])\n",
    "        print (\"Labels:\")\n",
    "        print (labels[0:5])\n",
    "\n",
    "\n",
    "    # Converts: label=True -> {\"POSITIVE\": True, \"NEGATIVE\": False}\n",
    "    # label=False -> {\"POSITIVE\": False, \"NEGATIVE\": True}\n",
    "    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n",
    "    if (debug >= 1):\n",
    "        print (\"Cats:\")\n",
    "        print (cats[0:5])\n",
    "\n",
    "    # Size of train_data and test_data\n",
    "    split = int(len(train_data) * split)\n",
    "    if (debug >= 1):\n",
    "        print (\"Train data:\", split, \"Test data: \", len(train_data)-split)   \n",
    "        print (\"\")\n",
    "    \n",
    "    # Return train data and test data\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "                if (debug >= 2):\n",
    "                    print (\"fp: \", doc)\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "                if (debug >= 2):\n",
    "                    print (\"fn: \", doc)                \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (model=None, output_dir=None, n_iter=20, n_texts=2000, init_tok2vec=None):\n",
    "    \n",
    "    # Load the model form spacy\n",
    "    nlp = spacy.load(model)\n",
    "\n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    # add label to text classifier\n",
    "    textcat.add_label(\"POSITIVE\")\n",
    "    textcat.add_label(\"NEGATIVE\")\n",
    "\n",
    "    # load training and test data\n",
    "    (train_texts, train_cats), (dev_texts, dev_cats) = load_data(0, 0.8, \"ca\")\n",
    "    train_texts = train_texts[:n_texts]\n",
    "    train_cats = train_cats[:n_texts]\n",
    "\n",
    "    if debug:\n",
    "        print(\n",
    "            \"Using {} examples ({} training, {} evaluation)\".format(\n",
    "                n_texts, len(train_texts), len(dev_texts)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # converts the data to the format:\n",
    "    # (text, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}))\n",
    "    train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "    if debug:\n",
    "        print (\"Train_data: \")\n",
    "        print (train_data[:5])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "        if init_tok2vec is not None:\n",
    "            with init_tok2vec.open(\"rb\") as file_:\n",
    "                textcat.model.tok2vec.from_bytes(file_.read())\n",
    "        print(\"Training the model...\")\n",
    "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                if (debug >= 2):\n",
    "                    print (\"Batch: \")\n",
    "                    print (batch)\n",
    "                texts, annotations = zip(*batch)\n",
    "\n",
    "                # Eliminación del 20% de los casos para evitar generalizaciones\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print(\n",
    "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(  # print a simple table\n",
    "                    losses[\"textcat\"],\n",
    "                    scores[\"textcat_p\"],\n",
    "                    scores[\"textcat_r\"],\n",
    "                    scores[\"textcat_f\"],\n",
    "                )\n",
    "            )  \n",
    "           \n",
    "    # test the trained model\n",
    "    print (\"\")\n",
    "    print (\"Some examples: \")\n",
    "    test_texts = [\"Costa que pengi els materials acordats al campus\",\n",
    "        \"No he tingut aquesta professora\",\n",
    "        \"No ha impartit classe a aquest grup\",\n",
    "        \"No ha corregit examens fets a octubre, i estem al mes de gener.\"]\n",
    "    for test_text in test_texts:\n",
    "        doc = nlp(test_text)\n",
    "        print(test_text, doc.cats)\n",
    "    print (\"\")\n",
    "    \n",
    "    # Save de model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "        \n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        for test_text in test_texts:\n",
    "            doc2 = nlp2(test_text)\n",
    "            print(test_text, doc2.cats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathori = \"../data/original\"\n",
    "pathdest = \"../data/preprocessed/\"\n",
    "pathmodel = \"../data/processed/\"\n",
    "debug = 1\n",
    "\n",
    "model = \"ca_fasttext_wiki\"\n",
    "output_dir = \"../data/processed/\"\n",
    "n_iter = 5\n",
    "n_texts = 2000\n",
    "init_tok2vec=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD_DATA\n",
      "Texts:\n",
      "(\"Molt bon professor, ho explica tot d'una manera molt clara, entenedora i professional\", \"És un bon professor, tot i que moltes vegades no ens acaba d'aclarar els dubtes que tenim ni penjar el material que necessitem.\", \"Crec que no ha set conscient que la seva assignatura no ere l'única de la carrera i no ens ha escolatat ni tingut en compte la nostra opinió en cap moment. \", \"Alguns treballs s'haurien de replantejar.\\r\\nL'assignatura la vam cursar durant horari d'avaluacions, és a dir, fora del plaç i abans de l'incici de la resta d'assignatures.\", 'Molt bona professora, i molt pràctica amb la seva experiència a les classes.')\n",
      "Labels:\n",
      "(False, False, False, False, False)\n",
      "Cats:\n",
      "[{'POSITIVE': False, 'NEGATIVE': True}, {'POSITIVE': False, 'NEGATIVE': True}, {'POSITIVE': False, 'NEGATIVE': True}, {'POSITIVE': False, 'NEGATIVE': True}, {'POSITIVE': False, 'NEGATIVE': True}]\n",
      "Train data: 2690 Test data:  673\n",
      "\n",
      "Using 2000 examples (2000 training, 673 evaluation)\n",
      "Train_data: \n",
      "[(\"Molt bon professor, ho explica tot d'una manera molt clara, entenedora i professional\", {'cats': {'POSITIVE': False, 'NEGATIVE': True}}), (\"És un bon professor, tot i que moltes vegades no ens acaba d'aclarar els dubtes que tenim ni penjar el material que necessitem.\", {'cats': {'POSITIVE': False, 'NEGATIVE': True}}), (\"Crec que no ha set conscient que la seva assignatura no ere l'única de la carrera i no ens ha escolatat ni tingut en compte la nostra opinió en cap moment. \", {'cats': {'POSITIVE': False, 'NEGATIVE': True}}), (\"Alguns treballs s'haurien de replantejar.\\r\\nL'assignatura la vam cursar durant horari d'avaluacions, és a dir, fora del plaç i abans de l'incici de la resta d'assignatures.\", {'cats': {'POSITIVE': False, 'NEGATIVE': True}}), ('Molt bona professora, i molt pràctica amb la seva experiència a les classes.', {'cats': {'POSITIVE': False, 'NEGATIVE': True}})]\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "fn:  Aquest professor no m'ha impartit l'assignatura. Només m'ha penjat un PDF i unes instruccions per fer un treball amb el qual puntuar-nos. Això no és docència.\n",
      "fn:  No el vam tenir com a professor en aquesta assignatura.\n",
      "Era el coordinador, però no ens va fer classe, ni presencial ni virtual.\n",
      "fp:  Només l'hem tingut en algunes classes online per tant no puc avaluar. \n",
      "fn:  Només va venir un dia a la sortida de camp. \n",
      "fn:  Sols vam poder realitzar una sortida amb aquest professor.\n",
      "0.419\t0.750\t0.429\t0.545\n",
      "fn:  Aquest professor no m'ha impartit l'assignatura. Només m'ha penjat un PDF i unes instruccions per fer un treball amb el qual puntuar-nos. Això no és docència.\n",
      "fn:  No el vam tenir com a professor en aquesta assignatura.\n",
      "Era el coordinador, però no ens va fer classe, ni presencial ni virtual.\n",
      "fn:  No l'hem tingut cap dia. No el conec ni sé qui és.\n",
      "fn:  Només va venir un dia a la sortida de camp. \n",
      "fn:  Sols vam poder realitzar una sortida amb aquest professor.\n",
      "0.066\t1.000\t0.286\t0.444\n",
      "fn:  Aquest professor no m'ha impartit l'assignatura. Només m'ha penjat un PDF i unes instruccions per fer un treball amb el qual puntuar-nos. Això no és docència.\n",
      "fn:  No el vam tenir com a professor en aquesta assignatura.\n",
      "Era el coordinador, però no ens va fer classe, ni presencial ni virtual.\n",
      "fn:  No l'hem tingut cap dia. No el conec ni sé qui és.\n",
      "fn:  Només va venir un dia a la sortida de camp. \n",
      "fn:  Sols vam poder realitzar una sortida amb aquest professor.\n",
      "0.006\t1.000\t0.286\t0.444\n",
      "fn:  No el vam tenir com a professor en aquesta assignatura.\n",
      "Era el coordinador, però no ens va fer classe, ni presencial ni virtual.\n",
      "fn:  No l'hem tingut cap dia. No el conec ni sé qui és.\n",
      "fn:  Només va venir un dia a la sortida de camp. \n",
      "fn:  Sols vam poder realitzar una sortida amb aquest professor.\n",
      "0.001\t1.000\t0.429\t0.600\n",
      "fn:  No el vam tenir com a professor en aquesta assignatura.\n",
      "Era el coordinador, però no ens va fer classe, ni presencial ni virtual.\n",
      "fn:  Només va venir un dia a la sortida de camp. \n",
      "fn:  Sols vam poder realitzar una sortida amb aquest professor.\n",
      "0.001\t1.000\t0.571\t0.727\n",
      "\n",
      "Some examples: \n",
      "Costa que pengi els materials acordats al campus {'POSITIVE': 6.013460733811371e-07, 'NEGATIVE': 0.9999994039535522}\n",
      "No he tingut aquesta professora {'POSITIVE': 0.9999995231628418, 'NEGATIVE': 4.4562446532836475e-07}\n",
      "No ha impartit classe a aquest grup {'POSITIVE': 0.995027482509613, 'NEGATIVE': 0.00497246440500021}\n",
      "No ha corregit examens fets a octubre, i estem al mes de gener. {'POSITIVE': 1.8729835574049503e-05, 'NEGATIVE': 0.9999812841415405}\n",
      "\n",
      "Saved model to ../data/processed/\n",
      "Loading from ../data/processed/\n",
      "Costa que pengi els materials acordats al campus {'POSITIVE': 1.1680458555929363e-06, 'NEGATIVE': 0.9999988079071045}\n",
      "No he tingut aquesta professora {'POSITIVE': 0.9999983310699463, 'NEGATIVE': 1.617339421500219e-06}\n",
      "No ha impartit classe a aquest grup {'POSITIVE': 0.994500994682312, 'NEGATIVE': 0.005498984362930059}\n",
      "No ha corregit examens fets a octubre, i estem al mes de gener. {'POSITIVE': 5.5080872698454186e-05, 'NEGATIVE': 0.9999449253082275}\n"
     ]
    }
   ],
   "source": [
    "main (model, output_dir, n_iter, n_texts, init_tok2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
