{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Tipus incidència 'No ha impartit classe a aquest grup'\n",
    "## Part-of-speech method\n",
    "\n",
    "En este notebook se va ha intendar mejorar el modelo de detección de la incidencia \n",
    "'No ha impartit classe a aquest grup' mediante el uso de Part-of-Speech y Dependency Parsing.\n",
    "\n",
    "Aquí se evaluarán las reglas definidas con los datos de muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#import os.path\n",
    "#import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import unicode_literals, print_function\n",
    "#import plac\n",
    "#import random\n",
    "#from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(language):\n",
    "    \n",
    "    if (debug >= 1):\n",
    "        print (\"LOAD_DATA\")\n",
    "        \n",
    "    # Load data from file\n",
    "    file = \"comentaris_\" + language + \".csv\"\n",
    "    data = pd.read_csv(pathdest + file)\n",
    "    if (debug >= 1):\n",
    "        print (\"Original data:\", data.shape[0])\n",
    "    if (debug >= 2):\n",
    "        display (data.sample(5))\n",
    "        \n",
    "    # Calculates label and filter rows to be used    \n",
    "    data_prof = data[data.TipusPregunta == \"P\"][[\"Comentari\",\"TipusIncidencia\"]]\n",
    "    if (debug >= 1):\n",
    "        print(\"Filtered data: \", data_prof.shape[0])        \n",
    "    if (debug >= 2):\n",
    "        display (data_prof.sample(5))\n",
    "        \n",
    "    # Calculates labels\n",
    "    data_prof[\"label\"] = data_prof[\"TipusIncidencia\"] == \"No ha impartit classe a aquest grup\"    \n",
    "    data_fin = data_prof[[\"Comentari\",\"label\"]]\n",
    "    \n",
    "    if (debug >= 1):\n",
    "        print (\"Final data:\", data_fin.shape[0])\n",
    "    if (debug >= 2):\n",
    "        display (data_fin.sample(5))\n",
    "        \n",
    "    return data_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matcher(nlp):\n",
    "    \n",
    "    if (debug >= 1):\n",
    "        print (\"TRAIN MATCHER\")\n",
    "  \n",
    "    # Rule-based matching\n",
    "    matcher = Matcher(nlp.vocab, validate=True)\n",
    "\n",
    "    adv_negs = [\"no\",\"tampoco\"]\n",
    "    verbs = [\"tratar\",\"ir\",\"conocer\",\"ver\",\"saber\",\"ser\",\"aparecer\",\"tener\"]\n",
    "    verbs_trans = [\"realizar\",\"dar\",\"recibir\",\"dictar\"]\n",
    "    noms_trans = [\"clase\",\"asignatura\"]\n",
    "\n",
    "    # Example: \"No he tratado con é\", \"No traté\", \"No he recibido\", \"No recibí\"\n",
    "    pattern = [{\"POS\": \"ADV\",\"LOWER\":{\"IN\":adv_negs}}, {\"OP\": \"*\"}, \n",
    "               {\"DEP\":\"ROOT\",\"POS\": \"VERB\", \"LEMMA\": {\"IN\": verbs}}]\n",
    "    matcher.add(\"NoClasses1\", None, pattern)\n",
    "\n",
    "    # Example: \"No ha realizado clases\"\n",
    "    pattern = [{\"POS\": \"ADV\",\"LOWER\":{\"IN\":adv_negs}}, {\"OP\": \"*\"}, \n",
    "               {\"DEP\":\"ROOT\",\"POS\": \"VERB\", \"LEMMA\": {\"IN\": verbs_trans}},\n",
    "               {\"OP\": \"*\"}, {\"POS\":\"NOUN\",\"LEMMA\":{\"IN\":noms_trans}}]\n",
    "    matcher.add(\"NoClasses3\", None, pattern)\n",
    "\n",
    "    if (debug >= 1):\n",
    "        print (\"Patterns: \", len(matcher))\n",
    "    \n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matching(nlp, matcher, text):\n",
    "    \n",
    "    predict = False;\n",
    "    if (debug >= 2):\n",
    "        print (\"PREDICT TEXT:\")\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        if (debug >= 2):\n",
    "            print (sent.text)\n",
    "            \n",
    "        matches = matcher(sent)\n",
    "        if (len(matches) == 0):\n",
    "            if (debug >= 2):\n",
    "                print (\"No matches\")\n",
    "#            return False\n",
    "        else:\n",
    "            match_id, start, end = matches[len(matches)-1]\n",
    "            string_id = nlp.vocab.strings[match_id] # Get string representation\n",
    "            span = sent[start:end] # The matched span\n",
    "            if (debug >= 2):\n",
    "                print (match_id, string_id, start, end, span.text)\n",
    "            predict = True\n",
    "        \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(nlp, matcher, data):\n",
    "    fp_list = list()\n",
    "    fn_list = list()\n",
    "\n",
    "    if (debug == 1):\n",
    "        print (\"EVALUATE\")\n",
    "\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        text = row[\"Comentari\"]\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        result = test_matching (nlp, matcher, text)\n",
    "\n",
    "        if (label == True):\n",
    "            if (result == True):\n",
    "                tp += 1.0\n",
    "            else:\n",
    "                fn += 1.0\n",
    "                fn_list.append(text)\n",
    "            if (debug >= 2):\n",
    "                print (\"fn: \", text)    \n",
    "        else:\n",
    "            if (result == True):\n",
    "                fp += 1.0\n",
    "                fp_list.append(text)\n",
    "                if (debug >= 2):\n",
    "                    print (\"fp: \", text)              \n",
    "            else:\n",
    "                tn += 1.0\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score, \n",
    "            \"false_positive\": fp_list, \"false_negative\": fn_list}\n",
    "    \n",
    "    \n",
    "    \n",
    "#    print (text, label, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathori = \"../data/original\"\n",
    "pathdest = \"../data/preprocessed/\"\n",
    "pathmodel = \"../data/models/\"\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD_DATA\n",
      "Original data: 1761\n",
      "Filtered data:  942\n",
      "Final data: 942\n"
     ]
    }
   ],
   "source": [
    "languages = {\"ca\":\"ca_fasttext_wiki\", \"es\":\"es_core_news_sm\", \"en\":\"en_core_web_sm\" }\n",
    "#languages = {\"es\":\"es_core_news_lg\"}\n",
    "\n",
    "language = \"es\"\n",
    "model = languages[language]\n",
    "\n",
    "# Load the model form spacy\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "data = load_data(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN MATCHER\n",
      "Patterns:  2\n",
      "EVALUATE\n",
      "Precission (p):  0.37499999995312494\n",
      "Recall (r):  0.7894736840027701\n",
      "F-score (f):  0.5084745761850042\n",
      "False positives:  50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['No vimos a en clase a este docente ',\n",
       " 'No lo sé porque no dictó clases. Debería controlar que el docente que sí lo hizo cumpla con el horario',\n",
       " 'facilita bastantes conocimientos sobre los aspectos que trata. desde el principio no se sabe qué se va a ensenar y por qué. la evaluacion es complicada. dificil saber qué espera exactamente y qué ha ha sido bueno o malo despues de la evaluacion. ',\n",
       " 'Joan Lluis no tiene una formación docente y eso se nota. Es accesible y amable con los estudiantes pero sus métodos no son claros. Las consignas de los trabajos no tienen concordancia con lo visto en clase y no proporciona bibliografía más que el power point de clase, que es armado por él. Esto hacer que la información vertida allí sea poco contrastable y hasta opinable. Sin embargo, creo que las clases han sido interesantes, he aprendido cosas nuevas. ',\n",
       " 'Creo que no se adapta para nada a la situación que estamos viviendo, he visto una clara diferencia entre esta asignaturas y las demás respecto al interés en intentar que esto sea más fácil para todos y poder llevar lo mejor posible y en esta asignatura no he tenido esta sensación, ni estoy satisfecha por esa parte. No he realizado las 2 horas de clase como sale en mi respectivo horario, igual que no siento por parte del profesor un interés o  ganas de enseñarnos. Correos no contestados, dudas que tenemos no respuestas o sin querer ser contestadas (donde como pruebas hay clases grabadas). El sistema de evaluación no ha cambiado, sigue teniendo un peso de un 50% un examen final y bastantes trabajos extensos o colaboraciones obligatorias en el fòrum con un peso de tan sólo un 5%. Me siento tirada al mar sin saber nadar y sin que nadie me enseñe. ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives:  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['El aspecto positivo es su personalidad y el interés porque aprendamos.\\nEn negativo, esperaba que nos hubiese dado ella una clase para poder valorarla. ',\n",
       " 'No fue nunca a clases',\n",
       " 'La clase no la dictó ella. ',\n",
       " 'No se quien es',\n",
       " 'no se qui es aquet']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "matcher = train_matcher(nlp)\n",
    "scores = evaluate(nlp, matcher, data)\n",
    "\n",
    "print(\"Precission (p): \", scores[\"textcat_p\"])\n",
    "print(\"Recall (r): \", scores[\"textcat_r\"])\n",
    "print(\"F-score (f): \", scores[\"textcat_f\"])\n",
    "print(\"False positives: \", len(scores[\"false_positive\"]))\n",
    "display(scores[\"false_positive\"][0:5])\n",
    "print(\"False negatives: \", len(scores[\"false_negative\"]))\n",
    "display(scores[\"false_negative\"][0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
